{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import mat73\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "data_dict = mat73.loadmat('./JF2_pubdata.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert matlib datenum to python datetime\n",
    "\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def datenum_to_datetime(datenum):\n",
    "    \"\"\"\n",
    "    Convert Matlab datenum into Python datetime.\n",
    "    :param datenum: Date in datenum format\n",
    "    :return:        Datetime object corresponding to datenum.\n",
    "    \"\"\"\n",
    "    days = datenum % 1\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    return datetime.fromordinal(int(datenum)) \\\n",
    "           + timedelta(days=int(days)) \\\n",
    "           + timedelta(hours=int(hours)) \\\n",
    "           + timedelta(minutes=int(minutes)) \\\n",
    "           + timedelta(seconds=round(seconds)) \\\n",
    "           - timedelta(days=366)\n",
    "\n",
    "year_list=[]\n",
    "month_list=[]\n",
    "for i in  data_dict['unique_dates']:\n",
    "    yyyy=datenum_to_datetime(i).year\n",
    "    mm=datenum_to_datetime(i).month\n",
    "    year_list.append(yyyy)\n",
    "    month_list.append(mm)\n",
    "\n",
    "yq_list=[]\n",
    "for (m,y) in zip(month_list,year_list):\n",
    "    if np.isin(m,(1,2,3)):\n",
    "        yq=y*100+1\n",
    "    elif np.isin(m,(4,5,6)):\n",
    "        yq=y*100+2\n",
    "    elif np.isin(m,(7,8,9)):\n",
    "        yq=y*100+3\n",
    "    elif np.isin(m,(10,11,12)):\n",
    "        yq=y*100+4\n",
    "    yq_list.append(yq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8759, 206)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate target, the DTS scaled excess return\n",
    "data_dict['EXCESS_RETURN']\n",
    "data_dict['DTS'][data_dict['DTS']<0.25]=0.25\n",
    "target=data_dict['EXCESS_RETURN']/data_dict['DTS']\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=np.hstack((data_dict['CHARS'][:,:-1,:],np.expand_dims(target,1))) #shape=[#bonds,#variables,#month][8759,30,206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8759, 30, 206)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = final_data[125,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = chunk.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(np.argwhere(np.isnan(chunk))[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "195\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "148\n",
      "161\n",
      "97\n",
      "162\n",
      "132\n",
      "148\n",
      "176\n",
      "195\n",
      "111\n",
      "184\n",
      "201\n",
      "182\n",
      "190\n",
      "100\n",
      "117\n",
      "133\n",
      "113\n",
      "162\n",
      "151\n",
      "133\n",
      "141\n",
      "152\n",
      "166\n",
      "181\n",
      "192\n",
      "189\n",
      "190\n",
      "190\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "206\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "142\n",
      "142\n",
      "154\n",
      "163\n",
      "204\n",
      "203\n",
      "179\n",
      "204\n",
      "179\n",
      "149\n",
      "41\n",
      "189\n",
      "61\n",
      "165\n",
      "65\n",
      "103\n",
      "176\n",
      "175\n",
      "103\n",
      "79\n",
      "160\n",
      "161\n",
      "109\n",
      "190\n",
      "162\n",
      "118\n",
      "162\n",
      "131\n",
      "131\n",
      "186\n",
      "165\n",
      "125\n",
      "188\n",
      "164\n",
      "140\n",
      "143\n",
      "191\n",
      "190\n",
      "153\n",
      "153\n",
      "153\n",
      "166\n",
      "163\n",
      "162\n",
      "162\n",
      "201\n",
      "186\n",
      "183\n",
      "168\n",
      "183\n",
      "167\n",
      "164\n",
      "164\n",
      "165\n",
      "164\n",
      "164\n",
      "164\n",
      "173\n",
      "173\n",
      "178\n",
      "175\n",
      "175\n",
      "175\n",
      "175\n",
      "176\n",
      "197\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "196\n",
      "199\n",
      "199\n",
      "205\n",
      "203\n",
      "204\n",
      "203\n",
      "203\n",
      "203\n",
      "203\n",
      "204\n",
      "203\n",
      "203\n",
      "206\n",
      "206\n",
      "138\n",
      "138\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "193\n",
      "190\n",
      "174\n",
      "162\n",
      "141\n",
      "117\n",
      "185\n",
      "166\n",
      "140\n",
      "111\n",
      "118\n",
      "192\n",
      "95\n",
      "176\n",
      "155\n",
      "152\n",
      "197\n",
      "198\n",
      "194\n",
      "194\n",
      "194\n",
      "194\n",
      "196\n",
      "200\n",
      "176\n",
      "206\n",
      "206\n",
      "191\n",
      "191\n",
      "206\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "167\n",
      "167\n",
      "188\n",
      "182\n",
      "156\n",
      "156\n",
      "156\n",
      "187\n",
      "156\n",
      "175\n",
      "206\n",
      "193\n",
      "185\n",
      "165\n",
      "172\n",
      "101\n",
      "137\n",
      "161\n",
      "185\n",
      "199\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "179\n",
      "179\n",
      "180\n",
      "179\n",
      "160\n",
      "102\n",
      "150\n",
      "136\n",
      "191\n",
      "190\n",
      "159\n",
      "200\n",
      "175\n",
      "157\n",
      "157\n",
      "162\n",
      "156\n",
      "167\n",
      "179\n",
      "174\n",
      "180\n",
      "184\n",
      "187\n",
      "186\n",
      "191\n",
      "194\n",
      "198\n",
      "198\n",
      "201\n",
      "175\n",
      "175\n",
      "145\n",
      "206\n",
      "206\n",
      "161\n",
      "126\n",
      "206\n",
      "140\n",
      "162\n",
      "206\n",
      "201\n",
      "206\n",
      "196\n",
      "183\n",
      "161\n",
      "185\n",
      "206\n",
      "206\n",
      "206\n",
      "197\n",
      "206\n",
      "177\n",
      "153\n",
      "153\n",
      "188\n",
      "161\n",
      "185\n",
      "170\n",
      "169\n",
      "181\n",
      "176\n",
      "180\n",
      "186\n",
      "185\n",
      "187\n",
      "191\n",
      "194\n",
      "194\n",
      "198\n",
      "166\n",
      "177\n",
      "162\n",
      "126\n",
      "141\n",
      "162\n",
      "147\n",
      "157\n",
      "171\n",
      "184\n",
      "201\n",
      "178\n",
      "180\n",
      "161\n",
      "187\n",
      "189\n",
      "152\n",
      "198\n",
      "185\n",
      "192\n",
      "148\n",
      "148\n",
      "206\n",
      "172\n",
      "172\n",
      "172\n",
      "206\n",
      "157\n",
      "166\n",
      "172\n",
      "206\n",
      "206\n",
      "206\n",
      "196\n",
      "195\n",
      "120\n",
      "107\n",
      "164\n",
      "113\n",
      "101\n",
      "101\n",
      "101\n",
      "105\n",
      "105\n",
      "161\n",
      "119\n",
      "143\n",
      "152\n",
      "206\n",
      "191\n",
      "197\n",
      "190\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "185\n",
      "136\n",
      "159\n",
      "206\n",
      "206\n",
      "174\n",
      "142\n",
      "166\n",
      "196\n",
      "190\n",
      "184\n",
      "163\n",
      "171\n",
      "151\n",
      "166\n",
      "166\n",
      "166\n",
      "165\n",
      "165\n",
      "182\n",
      "192\n",
      "200\n",
      "198\n",
      "191\n",
      "101\n",
      "161\n",
      "102\n",
      "132\n",
      "132\n",
      "173\n",
      "173\n",
      "204\n",
      "203\n",
      "155\n",
      "163\n",
      "162\n",
      "200\n",
      "185\n",
      "192\n",
      "206\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "202\n",
      "202\n",
      "206\n",
      "189\n",
      "204\n",
      "202\n",
      "206\n",
      "189\n",
      "206\n",
      "189\n",
      "189\n",
      "202\n",
      "183\n",
      "183\n",
      "199\n",
      "206\n",
      "206\n",
      "160\n",
      "161\n",
      "106\n",
      "77\n",
      "161\n",
      "96\n",
      "96\n",
      "160\n",
      "107\n",
      "121\n",
      "121\n",
      "129\n",
      "129\n",
      "182\n",
      "182\n",
      "160\n",
      "170\n",
      "170\n",
      "199\n",
      "199\n",
      "199\n",
      "199\n",
      "199\n",
      "199\n",
      "199\n",
      "197\n",
      "171\n",
      "126\n",
      "193\n",
      "175\n",
      "156\n",
      "149\n",
      "149\n",
      "149\n",
      "194\n",
      "191\n",
      "191\n",
      "191\n",
      "190\n",
      "191\n",
      "185\n",
      "176\n",
      "173\n",
      "173\n",
      "173\n",
      "173\n",
      "185\n",
      "196\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "178\n",
      "178\n",
      "186\n",
      "186\n",
      "188\n",
      "206\n",
      "206\n",
      "176\n",
      "137\n",
      "104\n",
      "161\n",
      "184\n",
      "196\n",
      "196\n",
      "206\n",
      "206\n",
      "187\n",
      "162\n",
      "101\n",
      "161\n",
      "161\n",
      "102\n",
      "101\n",
      "102\n",
      "161\n",
      "103\n",
      "127\n",
      "127\n",
      "167\n",
      "149\n",
      "180\n",
      "199\n",
      "198\n",
      "187\n",
      "190\n",
      "192\n",
      "196\n",
      "196\n",
      "199\n",
      "199\n",
      "202\n",
      "202\n",
      "206\n",
      "161\n",
      "161\n",
      "161\n",
      "161\n",
      "162\n",
      "165\n",
      "161\n",
      "187\n",
      "167\n",
      "167\n",
      "186\n",
      "165\n",
      "187\n",
      "162\n",
      "161\n",
      "166\n",
      "200\n",
      "184\n",
      "175\n",
      "200\n",
      "177\n",
      "165\n",
      "162\n",
      "161\n",
      "185\n",
      "204\n",
      "203\n",
      "190\n",
      "205\n",
      "201\n",
      "132\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "172\n",
      "186\n",
      "101\n",
      "185\n",
      "191\n",
      "193\n",
      "118\n",
      "137\n",
      "134\n",
      "162\n",
      "144\n",
      "150\n",
      "150\n",
      "156\n",
      "157\n",
      "156\n",
      "163\n",
      "164\n",
      "188\n",
      "188\n",
      "201\n",
      "206\n",
      "206\n",
      "164\n",
      "195\n",
      "166\n",
      "184\n",
      "195\n",
      "201\n",
      "205\n",
      "206\n",
      "194\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "176\n",
      "204\n",
      "193\n",
      "190\n",
      "156\n",
      "124\n",
      "116\n",
      "185\n",
      "151\n",
      "184\n",
      "185\n",
      "206\n",
      "206\n",
      "102\n",
      "134\n",
      "146\n",
      "200\n",
      "206\n",
      "206\n",
      "178\n",
      "178\n",
      "178\n",
      "206\n",
      "206\n",
      "202\n",
      "106\n",
      "109\n",
      "89\n",
      "103\n",
      "103\n",
      "79\n",
      "106\n",
      "98\n",
      "162\n",
      "114\n",
      "108\n",
      "185\n",
      "112\n",
      "161\n",
      "112\n",
      "118\n",
      "127\n",
      "162\n",
      "185\n",
      "166\n",
      "142\n",
      "160\n",
      "153\n",
      "153\n",
      "153\n",
      "174\n",
      "173\n",
      "176\n",
      "169\n",
      "169\n",
      "203\n",
      "189\n",
      "178\n",
      "183\n",
      "164\n",
      "137\n",
      "144\n",
      "160\n",
      "190\n",
      "185\n",
      "198\n",
      "198\n",
      "197\n",
      "206\n",
      "120\n",
      "20\n",
      "112\n",
      "179\n",
      "163\n",
      "176\n",
      "107\n",
      "161\n",
      "161\n",
      "108\n",
      "149\n",
      "164\n",
      "164\n",
      "178\n",
      "178\n",
      "178\n",
      "164\n",
      "161\n",
      "172\n",
      "172\n",
      "172\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "193\n",
      "206\n",
      "206\n",
      "206\n",
      "143\n",
      "143\n",
      "148\n",
      "157\n",
      "206\n",
      "164\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "140\n",
      "150\n",
      "172\n",
      "206\n",
      "194\n",
      "184\n",
      "184\n",
      "187\n",
      "184\n",
      "187\n",
      "187\n",
      "206\n",
      "179\n",
      "161\n",
      "198\n",
      "180\n",
      "177\n",
      "196\n",
      "201\n",
      "54\n",
      "116\n",
      "149\n",
      "164\n",
      "97\n",
      "117\n",
      "179\n",
      "125\n",
      "194\n",
      "203\n",
      "203\n",
      "204\n",
      "200\n",
      "202\n",
      "133\n",
      "129\n",
      "154\n",
      "141\n",
      "142\n",
      "181\n",
      "160\n",
      "151\n",
      "151\n",
      "181\n",
      "162\n",
      "154\n",
      "154\n",
      "173\n",
      "163\n",
      "163\n",
      "163\n",
      "163\n",
      "168\n",
      "178\n",
      "168\n",
      "175\n",
      "175\n",
      "175\n",
      "178\n",
      "184\n",
      "178\n",
      "178\n",
      "179\n",
      "182\n",
      "187\n",
      "182\n",
      "188\n",
      "185\n",
      "184\n",
      "184\n",
      "112\n",
      "107\n",
      "166\n",
      "158\n",
      "159\n",
      "176\n",
      "177\n",
      "200\n",
      "199\n",
      "176\n",
      "206\n",
      "198\n",
      "198\n",
      "204\n",
      "204\n",
      "186\n",
      "168\n",
      "122\n",
      "169\n",
      "154\n",
      "200\n",
      "204\n",
      "204\n",
      "206\n",
      "206\n",
      "127\n",
      "108\n",
      "117\n",
      "172\n",
      "196\n",
      "196\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "200\n",
      "200\n",
      "102\n",
      "179\n",
      "183\n",
      "204\n",
      "157\n",
      "183\n",
      "134\n",
      "198\n",
      "174\n",
      "134\n",
      "45\n",
      "205\n",
      "143\n",
      "149\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "105\n",
      "206\n",
      "206\n",
      "165\n",
      "200\n",
      "183\n",
      "206\n",
      "179\n",
      "158\n",
      "173\n",
      "124\n",
      "159\n",
      "184\n",
      "184\n",
      "205\n",
      "132\n",
      "145\n",
      "201\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "196\n",
      "178\n",
      "186\n",
      "191\n",
      "170\n",
      "182\n",
      "164\n",
      "206\n",
      "161\n",
      "128\n",
      "169\n",
      "192\n",
      "206\n",
      "193\n",
      "203\n",
      "196\n",
      "165\n",
      "192\n",
      "112\n",
      "100\n",
      "77\n",
      "42\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "172\n",
      "185\n",
      "197\n",
      "175\n",
      "150\n",
      "160\n",
      "185\n",
      "161\n",
      "162\n",
      "165\n",
      "164\n",
      "163\n",
      "165\n",
      "176\n",
      "186\n",
      "193\n",
      "193\n",
      "203\n",
      "200\n",
      "192\n",
      "186\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "186\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "200\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "182\n",
      "194\n",
      "186\n",
      "186\n",
      "186\n",
      "180\n",
      "135\n",
      "147\n",
      "173\n",
      "166\n",
      "159\n",
      "167\n",
      "115\n",
      "130\n",
      "188\n",
      "196\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "130\n",
      "171\n",
      "119\n",
      "171\n",
      "104\n",
      "101\n",
      "77\n",
      "160\n",
      "101\n",
      "161\n",
      "101\n",
      "136\n",
      "76\n",
      "104\n",
      "81\n",
      "160\n",
      "101\n",
      "102\n",
      "115\n",
      "116\n",
      "161\n",
      "185\n",
      "161\n",
      "126\n",
      "161\n",
      "185\n",
      "138\n",
      "138\n",
      "165\n",
      "140\n",
      "140\n",
      "145\n",
      "186\n",
      "147\n",
      "150\n",
      "164\n",
      "153\n",
      "163\n",
      "156\n",
      "164\n",
      "163\n",
      "167\n",
      "165\n",
      "171\n",
      "171\n",
      "183\n",
      "172\n",
      "132\n",
      "194\n",
      "161\n",
      "164\n",
      "124\n",
      "188\n",
      "190\n",
      "195\n",
      "200\n",
      "199\n",
      "174\n",
      "161\n",
      "202\n",
      "203\n",
      "200\n",
      "161\n",
      "164\n",
      "167\n",
      "165\n",
      "169\n",
      "169\n",
      "194\n",
      "164\n",
      "162\n",
      "161\n",
      "161\n",
      "164\n",
      "161\n",
      "166\n",
      "169\n",
      "165\n",
      "169\n",
      "111\n",
      "185\n",
      "161\n",
      "185\n",
      "193\n",
      "165\n",
      "167\n",
      "166\n",
      "165\n",
      "170\n",
      "138\n",
      "166\n",
      "142\n",
      "165\n",
      "164\n",
      "151\n",
      "189\n",
      "166\n",
      "162\n",
      "174\n",
      "178\n",
      "186\n",
      "186\n",
      "190\n",
      "189\n",
      "193\n",
      "206\n",
      "181\n",
      "188\n",
      "161\n",
      "168\n",
      "108\n",
      "168\n",
      "192\n",
      "161\n",
      "164\n",
      "165\n",
      "189\n",
      "186\n",
      "168\n",
      "148\n",
      "167\n",
      "161\n",
      "170\n",
      "190\n",
      "179\n",
      "191\n",
      "194\n",
      "199\n",
      "204\n",
      "204\n",
      "195\n",
      "196\n",
      "195\n",
      "195\n",
      "196\n",
      "198\n",
      "197\n",
      "179\n",
      "163\n",
      "142\n",
      "201\n",
      "162\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "120\n",
      "202\n",
      "194\n",
      "140\n",
      "140\n",
      "171\n",
      "171\n",
      "123\n",
      "182\n",
      "182\n",
      "155\n",
      "161\n",
      "111\n",
      "181\n",
      "125\n",
      "163\n",
      "187\n",
      "164\n",
      "193\n",
      "188\n",
      "180\n",
      "180\n",
      "169\n",
      "169\n",
      "173\n",
      "185\n",
      "177\n",
      "197\n",
      "197\n",
      "124\n",
      "196\n",
      "186\n",
      "201\n",
      "162\n",
      "169\n",
      "191\n",
      "162\n",
      "206\n",
      "171\n",
      "186\n",
      "206\n",
      "127\n",
      "122\n",
      "122\n",
      "187\n",
      "190\n",
      "175\n",
      "193\n",
      "190\n",
      "187\n",
      "194\n",
      "204\n",
      "112\n",
      "171\n",
      "189\n",
      "161\n",
      "149\n",
      "149\n",
      "197\n",
      "198\n",
      "185\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "144\n",
      "188\n",
      "203\n",
      "166\n",
      "166\n",
      "166\n",
      "171\n",
      "166\n",
      "189\n",
      "192\n",
      "192\n",
      "194\n",
      "194\n",
      "195\n",
      "166\n",
      "188\n",
      "166\n",
      "158\n",
      "206\n",
      "206\n",
      "206\n",
      "170\n",
      "149\n",
      "152\n",
      "193\n",
      "168\n",
      "162\n",
      "204\n",
      "204\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "166\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "164\n",
      "181\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "167\n",
      "162\n",
      "104\n",
      "162\n",
      "194\n",
      "206\n",
      "165\n",
      "102\n",
      "163\n",
      "158\n",
      "158\n",
      "158\n",
      "206\n",
      "162\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "164\n",
      "174\n",
      "163\n",
      "135\n",
      "170\n",
      "170\n",
      "170\n",
      "150\n",
      "168\n",
      "176\n",
      "203\n",
      "194\n",
      "135\n",
      "126\n",
      "176\n",
      "166\n",
      "116\n",
      "104\n",
      "164\n",
      "163\n",
      "112\n",
      "167\n",
      "111\n",
      "162\n",
      "105\n",
      "86\n",
      "159\n",
      "100\n",
      "89\n",
      "190\n",
      "148\n",
      "192\n",
      "193\n",
      "190\n",
      "171\n",
      "171\n",
      "182\n",
      "180\n",
      "192\n",
      "192\n",
      "192\n",
      "192\n",
      "200\n",
      "200\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "201\n",
      "201\n",
      "206\n",
      "152\n",
      "152\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "190\n",
      "206\n",
      "201\n",
      "167\n",
      "156\n",
      "171\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "201\n",
      "196\n",
      "191\n",
      "189\n",
      "189\n",
      "189\n",
      "184\n",
      "164\n",
      "176\n",
      "117\n",
      "149\n",
      "169\n",
      "124\n",
      "136\n",
      "136\n",
      "175\n",
      "164\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "200\n",
      "187\n",
      "169\n",
      "197\n",
      "201\n",
      "201\n",
      "167\n",
      "190\n",
      "176\n",
      "182\n",
      "186\n",
      "199\n",
      "176\n",
      "146\n",
      "165\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "189\n",
      "125\n",
      "107\n",
      "161\n",
      "161\n",
      "164\n",
      "172\n",
      "185\n",
      "185\n",
      "197\n",
      "206\n",
      "157\n",
      "136\n",
      "128\n",
      "143\n",
      "177\n",
      "185\n",
      "185\n",
      "196\n",
      "204\n",
      "175\n",
      "181\n",
      "156\n",
      "127\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "176\n",
      "175\n",
      "206\n",
      "206\n",
      "206\n",
      "199\n",
      "202\n",
      "199\n",
      "202\n",
      "186\n",
      "153\n",
      "158\n",
      "153\n",
      "154\n",
      "206\n",
      "206\n",
      "198\n",
      "205\n",
      "159\n",
      "177\n",
      "188\n",
      "203\n",
      "188\n",
      "198\n",
      "206\n",
      "206\n",
      "128\n",
      "104\n",
      "130\n",
      "130\n",
      "140\n",
      "140\n",
      "206\n",
      "189\n",
      "160\n",
      "168\n",
      "170\n",
      "163\n",
      "176\n",
      "197\n",
      "206\n",
      "179\n",
      "176\n",
      "176\n",
      "153\n",
      "182\n",
      "189\n",
      "205\n",
      "205\n",
      "205\n",
      "205\n",
      "205\n",
      "205\n",
      "206\n",
      "191\n",
      "206\n",
      "206\n",
      "202\n",
      "196\n",
      "206\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "205\n",
      "180\n",
      "160\n",
      "178\n",
      "137\n",
      "137\n",
      "164\n",
      "188\n",
      "188\n",
      "188\n",
      "193\n",
      "206\n",
      "185\n",
      "196\n",
      "161\n",
      "161\n",
      "125\n",
      "134\n",
      "152\n",
      "191\n",
      "192\n",
      "161\n",
      "119\n",
      "191\n",
      "206\n",
      "206\n",
      "199\n",
      "206\n",
      "183\n",
      "182\n",
      "182\n",
      "182\n",
      "193\n",
      "182\n",
      "184\n",
      "205\n",
      "188\n",
      "169\n",
      "136\n",
      "141\n",
      "183\n",
      "204\n",
      "206\n",
      "194\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "203\n",
      "117\n",
      "201\n",
      "146\n",
      "105\n",
      "58\n",
      "109\n",
      "136\n",
      "194\n",
      "125\n",
      "174\n",
      "174\n",
      "123\n",
      "145\n",
      "153\n",
      "160\n",
      "171\n",
      "171\n",
      "171\n",
      "178\n",
      "187\n",
      "187\n",
      "188\n",
      "196\n",
      "196\n",
      "200\n",
      "206\n",
      "180\n",
      "167\n",
      "163\n",
      "103\n",
      "161\n",
      "101\n",
      "109\n",
      "59\n",
      "131\n",
      "103\n",
      "162\n",
      "107\n",
      "124\n",
      "165\n",
      "137\n",
      "137\n",
      "162\n",
      "145\n",
      "161\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "167\n",
      "166\n",
      "166\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "198\n",
      "189\n",
      "205\n",
      "205\n",
      "205\n",
      "205\n",
      "159\n",
      "111\n",
      "199\n",
      "199\n",
      "206\n",
      "206\n",
      "177\n",
      "177\n",
      "181\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "121\n",
      "102\n",
      "163\n",
      "136\n",
      "120\n",
      "189\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "198\n",
      "167\n",
      "181\n",
      "190\n",
      "192\n",
      "189\n",
      "195\n",
      "162\n",
      "163\n",
      "169\n",
      "198\n",
      "188\n",
      "198\n",
      "175\n",
      "175\n",
      "175\n",
      "175\n",
      "179\n",
      "178\n",
      "178\n",
      "150\n",
      "156\n",
      "158\n",
      "178\n",
      "194\n",
      "145\n",
      "100\n",
      "161\n",
      "100\n",
      "161\n",
      "185\n",
      "161\n",
      "109\n",
      "185\n",
      "185\n",
      "134\n",
      "164\n",
      "141\n",
      "151\n",
      "159\n",
      "168\n",
      "176\n",
      "176\n",
      "185\n",
      "198\n",
      "198\n",
      "198\n",
      "198\n",
      "202\n",
      "202\n",
      "198\n",
      "127\n",
      "185\n",
      "185\n",
      "163\n",
      "145\n",
      "161\n",
      "186\n",
      "185\n",
      "185\n",
      "170\n",
      "198\n",
      "183\n",
      "174\n",
      "118\n",
      "81\n",
      "160\n",
      "107\n",
      "162\n",
      "167\n",
      "127\n",
      "162\n",
      "148\n",
      "157\n",
      "157\n",
      "179\n",
      "179\n",
      "179\n",
      "200\n",
      "179\n",
      "206\n",
      "184\n",
      "206\n",
      "206\n",
      "101\n",
      "113\n",
      "167\n",
      "177\n",
      "128\n",
      "172\n",
      "148\n",
      "194\n",
      "174\n",
      "192\n",
      "206\n",
      "206\n",
      "203\n",
      "176\n",
      "161\n",
      "163\n",
      "108\n",
      "161\n",
      "112\n",
      "106\n",
      "192\n",
      "109\n",
      "121\n",
      "194\n",
      "165\n",
      "125\n",
      "142\n",
      "142\n",
      "142\n",
      "186\n",
      "162\n",
      "184\n",
      "173\n",
      "163\n",
      "165\n",
      "163\n",
      "162\n",
      "103\n",
      "191\n",
      "171\n",
      "106\n",
      "161\n",
      "189\n",
      "193\n",
      "188\n",
      "171\n",
      "192\n",
      "188\n",
      "195\n",
      "167\n",
      "197\n",
      "191\n",
      "162\n",
      "120\n",
      "167\n",
      "136\n",
      "188\n",
      "167\n",
      "143\n",
      "168\n",
      "148\n",
      "166\n",
      "189\n",
      "172\n",
      "179\n",
      "187\n",
      "192\n",
      "188\n",
      "185\n",
      "193\n",
      "199\n",
      "190\n",
      "196\n",
      "201\n",
      "198\n",
      "200\n",
      "202\n",
      "204\n",
      "180\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "177\n",
      "106\n",
      "125\n",
      "201\n",
      "155\n",
      "161\n",
      "121\n",
      "161\n",
      "142\n",
      "154\n",
      "167\n",
      "163\n",
      "166\n",
      "163\n",
      "178\n",
      "178\n",
      "178\n",
      "192\n",
      "178\n",
      "202\n",
      "204\n",
      "204\n",
      "204\n",
      "205\n",
      "172\n",
      "175\n",
      "175\n",
      "180\n",
      "179\n",
      "206\n",
      "153\n",
      "141\n",
      "180\n",
      "175\n",
      "173\n",
      "206\n",
      "185\n",
      "185\n",
      "168\n",
      "141\n",
      "181\n",
      "196\n",
      "196\n",
      "195\n",
      "205\n",
      "205\n",
      "177\n",
      "188\n",
      "198\n",
      "161\n",
      "206\n",
      "206\n",
      "206\n",
      "181\n",
      "191\n",
      "9\n",
      "136\n",
      "131\n",
      "100\n",
      "87\n",
      "101\n",
      "149\n",
      "108\n",
      "117\n",
      "117\n",
      "136\n",
      "137\n",
      "160\n",
      "165\n",
      "153\n",
      "197\n",
      "192\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "189\n",
      "189\n",
      "192\n",
      "206\n",
      "203\n",
      "203\n",
      "133\n",
      "126\n",
      "200\n",
      "206\n",
      "190\n",
      "206\n",
      "206\n",
      "200\n",
      "187\n",
      "190\n",
      "190\n",
      "157\n",
      "140\n",
      "142\n",
      "149\n",
      "149\n",
      "158\n",
      "158\n",
      "159\n",
      "136\n",
      "155\n",
      "174\n",
      "204\n",
      "180\n",
      "106\n",
      "197\n",
      "164\n",
      "168\n",
      "169\n",
      "124\n",
      "147\n",
      "131\n",
      "171\n",
      "167\n",
      "155\n",
      "174\n",
      "160\n",
      "175\n",
      "166\n",
      "166\n",
      "180\n",
      "175\n",
      "206\n",
      "206\n",
      "165\n",
      "185\n",
      "164\n",
      "109\n",
      "115\n",
      "127\n",
      "127\n",
      "153\n",
      "181\n",
      "181\n",
      "184\n",
      "158\n",
      "158\n",
      "142\n",
      "177\n",
      "200\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "130\n",
      "182\n",
      "180\n",
      "176\n",
      "176\n",
      "165\n",
      "106\n",
      "79\n",
      "108\n",
      "88\n",
      "178\n",
      "102\n",
      "205\n",
      "166\n",
      "142\n",
      "155\n",
      "164\n",
      "155\n",
      "171\n",
      "163\n",
      "172\n",
      "173\n",
      "174\n",
      "170\n",
      "203\n",
      "137\n",
      "177\n",
      "176\n",
      "124\n",
      "165\n",
      "18\n",
      "160\n",
      "25\n",
      "94\n",
      "148\n",
      "118\n",
      "164\n",
      "123\n",
      "171\n",
      "118\n",
      "176\n",
      "197\n",
      "118\n",
      "179\n",
      "154\n",
      "119\n",
      "67\n",
      "178\n",
      "119\n",
      "179\n",
      "120\n",
      "179\n",
      "179\n",
      "120\n",
      "85\n",
      "176\n",
      "117\n",
      "172\n",
      "105\n",
      "84\n",
      "161\n",
      "160\n",
      "161\n",
      "179\n",
      "103\n",
      "202\n",
      "162\n",
      "114\n",
      "174\n",
      "186\n",
      "184\n",
      "186\n",
      "179\n",
      "127\n",
      "185\n",
      "163\n",
      "130\n",
      "134\n",
      "134\n",
      "163\n",
      "135\n",
      "179\n",
      "185\n",
      "185\n",
      "166\n",
      "141\n",
      "144\n",
      "162\n",
      "144\n",
      "186\n",
      "148\n",
      "187\n",
      "185\n",
      "163\n",
      "152\n",
      "153\n",
      "155\n",
      "190\n",
      "158\n",
      "162\n",
      "162\n",
      "164\n",
      "194\n",
      "165\n",
      "166\n",
      "187\n",
      "168\n",
      "169\n",
      "171\n",
      "173\n",
      "186\n",
      "177\n",
      "183\n",
      "192\n",
      "176\n",
      "145\n",
      "201\n",
      "186\n",
      "187\n",
      "196\n",
      "192\n",
      "147\n",
      "161\n",
      "147\n",
      "176\n",
      "205\n",
      "205\n",
      "205\n",
      "194\n",
      "204\n",
      "184\n",
      "152\n",
      "145\n",
      "148\n",
      "204\n",
      "206\n",
      "148\n",
      "154\n",
      "157\n",
      "158\n",
      "158\n",
      "165\n",
      "174\n",
      "177\n",
      "177\n",
      "206\n",
      "206\n",
      "199\n",
      "200\n",
      "195\n",
      "134\n",
      "185\n",
      "179\n",
      "177\n",
      "122\n",
      "190\n",
      "206\n",
      "188\n",
      "191\n",
      "122\n",
      "132\n",
      "167\n",
      "147\n",
      "202\n",
      "189\n",
      "119\n",
      "128\n",
      "204\n",
      "163\n",
      "135\n",
      "139\n",
      "153\n",
      "159\n",
      "180\n",
      "169\n",
      "178\n",
      "190\n",
      "145\n",
      "172\n",
      "114\n",
      "178\n",
      "142\n",
      "186\n",
      "184\n",
      "200\n",
      "153\n",
      "180\n",
      "186\n",
      "204\n",
      "180\n",
      "174\n",
      "173\n",
      "206\n",
      "188\n",
      "197\n",
      "206\n",
      "199\n",
      "190\n",
      "188\n",
      "189\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "197\n",
      "197\n",
      "168\n",
      "168\n",
      "175\n",
      "175\n",
      "175\n",
      "188\n",
      "188\n",
      "194\n",
      "194\n",
      "203\n",
      "203\n",
      "203\n",
      "101\n",
      "165\n",
      "202\n",
      "198\n",
      "118\n",
      "130\n",
      "179\n",
      "198\n",
      "162\n",
      "176\n",
      "103\n",
      "104\n",
      "189\n",
      "160\n",
      "167\n",
      "181\n",
      "187\n",
      "193\n",
      "199\n",
      "194\n",
      "206\n",
      "206\n",
      "190\n",
      "187\n",
      "103\n",
      "170\n",
      "177\n",
      "136\n",
      "171\n",
      "190\n",
      "177\n",
      "111\n",
      "161\n",
      "185\n",
      "185\n",
      "161\n",
      "126\n",
      "195\n",
      "195\n",
      "195\n",
      "195\n",
      "195\n",
      "195\n",
      "184\n",
      "197\n",
      "158\n",
      "154\n",
      "152\n",
      "157\n",
      "175\n",
      "182\n",
      "182\n",
      "192\n",
      "192\n",
      "189\n",
      "80\n",
      "106\n",
      "9\n",
      "168\n",
      "109\n",
      "70\n",
      "78\n",
      "117\n",
      "155\n",
      "123\n",
      "138\n",
      "102\n",
      "201\n",
      "173\n",
      "126\n",
      "166\n",
      "148\n",
      "148\n",
      "181\n",
      "187\n",
      "192\n",
      "164\n",
      "164\n",
      "197\n",
      "180\n",
      "177\n",
      "161\n",
      "104\n",
      "78\n",
      "104\n",
      "127\n",
      "140\n",
      "149\n",
      "161\n",
      "168\n",
      "179\n",
      "191\n",
      "197\n",
      "196\n",
      "202\n",
      "168\n",
      "185\n",
      "169\n",
      "109\n",
      "154\n",
      "128\n",
      "101\n",
      "109\n",
      "136\n",
      "148\n",
      "130\n",
      "129\n",
      "162\n",
      "147\n",
      "161\n",
      "172\n",
      "178\n",
      "178\n",
      "178\n",
      "196\n",
      "189\n",
      "183\n",
      "186\n",
      "186\n",
      "186\n",
      "195\n",
      "195\n",
      "195\n",
      "204\n",
      "165\n",
      "117\n",
      "136\n",
      "206\n",
      "117\n",
      "170\n",
      "195\n",
      "195\n",
      "203\n",
      "205\n",
      "179\n",
      "193\n",
      "180\n",
      "181\n",
      "153\n",
      "146\n",
      "194\n",
      "206\n",
      "206\n",
      "198\n",
      "198\n",
      "184\n",
      "195\n",
      "206\n",
      "163\n",
      "138\n",
      "174\n",
      "206\n",
      "206\n",
      "198\n",
      "163\n",
      "106\n",
      "179\n",
      "154\n",
      "167\n",
      "166\n",
      "195\n",
      "187\n",
      "178\n",
      "178\n",
      "175\n",
      "187\n",
      "199\n",
      "142\n",
      "200\n",
      "206\n",
      "173\n",
      "142\n",
      "140\n",
      "140\n",
      "176\n",
      "196\n",
      "150\n",
      "206\n",
      "201\n",
      "190\n",
      "190\n",
      "190\n",
      "190\n",
      "190\n",
      "190\n",
      "192\n",
      "200\n",
      "204\n",
      "204\n",
      "184\n",
      "160\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "201\n",
      "196\n",
      "178\n",
      "206\n",
      "198\n",
      "135\n",
      "206\n",
      "185\n",
      "198\n",
      "171\n",
      "167\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "155\n",
      "202\n",
      "185\n",
      "191\n",
      "193\n",
      "202\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "164\n",
      "186\n",
      "186\n",
      "175\n",
      "160\n",
      "122\n",
      "160\n",
      "133\n",
      "161\n",
      "162\n",
      "184\n",
      "199\n",
      "174\n",
      "114\n",
      "142\n",
      "205\n",
      "170\n",
      "176\n",
      "194\n",
      "203\n",
      "203\n",
      "181\n",
      "189\n",
      "199\n",
      "162\n",
      "195\n",
      "192\n",
      "162\n",
      "185\n",
      "162\n",
      "162\n",
      "179\n",
      "162\n",
      "164\n",
      "168\n",
      "173\n",
      "197\n",
      "193\n",
      "202\n",
      "175\n",
      "176\n",
      "176\n",
      "202\n",
      "182\n",
      "167\n",
      "170\n",
      "144\n",
      "149\n",
      "193\n",
      "169\n",
      "172\n",
      "158\n",
      "158\n",
      "156\n",
      "181\n",
      "177\n",
      "187\n",
      "188\n",
      "164\n",
      "157\n",
      "157\n",
      "174\n",
      "164\n",
      "134\n",
      "146\n",
      "155\n",
      "195\n",
      "113\n",
      "180\n",
      "84\n",
      "106\n",
      "120\n",
      "119\n",
      "172\n",
      "109\n",
      "163\n",
      "161\n",
      "104\n",
      "188\n",
      "188\n",
      "173\n",
      "185\n",
      "184\n",
      "174\n",
      "165\n",
      "163\n",
      "164\n",
      "161\n",
      "105\n",
      "167\n",
      "107\n",
      "178\n",
      "191\n",
      "141\n",
      "166\n",
      "114\n",
      "113\n",
      "196\n",
      "165\n",
      "118\n",
      "168\n",
      "197\n",
      "143\n",
      "197\n",
      "122\n",
      "167\n",
      "139\n",
      "170\n",
      "146\n",
      "169\n",
      "167\n",
      "169\n",
      "168\n",
      "167\n",
      "167\n",
      "177\n",
      "190\n",
      "191\n",
      "179\n",
      "184\n",
      "183\n",
      "197\n",
      "188\n",
      "186\n",
      "192\n",
      "188\n",
      "192\n",
      "197\n",
      "195\n",
      "200\n",
      "200\n",
      "202\n",
      "201\n",
      "206\n",
      "203\n",
      "204\n",
      "155\n",
      "163\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "194\n",
      "206\n",
      "194\n",
      "206\n",
      "206\n",
      "194\n",
      "195\n",
      "204\n",
      "176\n",
      "185\n",
      "184\n",
      "190\n",
      "189\n",
      "189\n",
      "203\n",
      "170\n",
      "206\n",
      "168\n",
      "193\n",
      "194\n",
      "194\n",
      "194\n",
      "197\n",
      "196\n",
      "196\n",
      "202\n",
      "195\n",
      "204\n",
      "206\n",
      "170\n",
      "194\n",
      "194\n",
      "194\n",
      "206\n",
      "194\n",
      "194\n",
      "194\n",
      "202\n",
      "198\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "203\n",
      "179\n",
      "172\n",
      "174\n",
      "185\n",
      "198\n",
      "191\n",
      "200\n",
      "28\n",
      "186\n",
      "179\n",
      "123\n",
      "189\n",
      "118\n",
      "155\n",
      "161\n",
      "178\n",
      "142\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "199\n",
      "158\n",
      "140\n",
      "148\n",
      "194\n",
      "206\n",
      "190\n",
      "198\n",
      "198\n",
      "191\n",
      "189\n",
      "193\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "196\n",
      "202\n",
      "177\n",
      "177\n",
      "196\n",
      "198\n",
      "205\n",
      "206\n",
      "206\n",
      "140\n",
      "161\n",
      "145\n",
      "186\n",
      "206\n",
      "163\n",
      "169\n",
      "166\n",
      "204\n",
      "193\n",
      "198\n",
      "170\n",
      "111\n",
      "162\n",
      "117\n",
      "117\n",
      "120\n",
      "202\n",
      "178\n",
      "126\n",
      "125\n",
      "196\n",
      "142\n",
      "172\n",
      "158\n",
      "174\n",
      "162\n",
      "194\n",
      "194\n",
      "194\n",
      "183\n",
      "178\n",
      "128\n",
      "149\n",
      "152\n",
      "175\n",
      "202\n",
      "111\n",
      "111\n",
      "164\n",
      "123\n",
      "129\n",
      "166\n",
      "150\n",
      "170\n",
      "191\n",
      "206\n",
      "178\n",
      "171\n",
      "136\n",
      "159\n",
      "176\n",
      "190\n",
      "197\n",
      "199\n",
      "189\n",
      "189\n",
      "189\n",
      "126\n",
      "196\n",
      "163\n",
      "149\n",
      "161\n",
      "101\n",
      "137\n",
      "203\n",
      "152\n",
      "187\n",
      "171\n",
      "161\n",
      "101\n",
      "35\n",
      "106\n",
      "104\n",
      "147\n",
      "102\n",
      "185\n",
      "126\n",
      "110\n",
      "161\n",
      "122\n",
      "165\n",
      "186\n",
      "185\n",
      "170\n",
      "170\n",
      "148\n",
      "158\n",
      "185\n",
      "169\n",
      "169\n",
      "198\n",
      "183\n",
      "190\n",
      "200\n",
      "203\n",
      "203\n",
      "206\n",
      "166\n",
      "177\n",
      "37\n",
      "118\n",
      "201\n",
      "144\n",
      "100\n",
      "188\n",
      "162\n",
      "107\n",
      "173\n",
      "119\n",
      "119\n",
      "188\n",
      "173\n",
      "137\n",
      "158\n",
      "149\n",
      "149\n",
      "161\n",
      "161\n",
      "183\n",
      "183\n",
      "183\n",
      "206\n",
      "206\n",
      "177\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "204\n",
      "134\n",
      "102\n",
      "168\n",
      "189\n",
      "175\n",
      "104\n",
      "161\n",
      "110\n",
      "165\n",
      "148\n",
      "167\n",
      "126\n",
      "135\n",
      "135\n",
      "160\n",
      "198\n",
      "164\n",
      "164\n",
      "107\n",
      "131\n",
      "107\n",
      "170\n",
      "167\n",
      "161\n",
      "77\n",
      "169\n",
      "185\n",
      "134\n",
      "195\n",
      "105\n",
      "105\n",
      "130\n",
      "206\n",
      "160\n",
      "101\n",
      "162\n",
      "109\n",
      "165\n",
      "163\n",
      "121\n",
      "163\n",
      "135\n",
      "141\n",
      "161\n",
      "169\n",
      "169\n",
      "169\n",
      "181\n",
      "181\n",
      "181\n",
      "204\n",
      "203\n",
      "94\n",
      "114\n",
      "178\n",
      "154\n",
      "165\n",
      "164\n",
      "173\n",
      "184\n",
      "187\n",
      "188\n",
      "196\n",
      "205\n",
      "205\n",
      "185\n",
      "199\n",
      "198\n",
      "206\n",
      "206\n",
      "171\n",
      "183\n",
      "193\n",
      "201\n",
      "170\n",
      "174\n",
      "191\n",
      "192\n",
      "206\n",
      "206\n",
      "206\n",
      "176\n",
      "174\n",
      "190\n",
      "190\n",
      "190\n",
      "180\n",
      "180\n",
      "180\n",
      "101\n",
      "163\n",
      "103\n",
      "160\n",
      "122\n",
      "149\n",
      "152\n",
      "152\n",
      "162\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "191\n",
      "182\n",
      "182\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "197\n",
      "195\n",
      "191\n",
      "186\n",
      "190\n",
      "181\n",
      "181\n",
      "192\n",
      "199\n",
      "168\n",
      "193\n",
      "202\n",
      "178\n",
      "203\n",
      "164\n",
      "120\n",
      "142\n",
      "160\n",
      "148\n",
      "196\n",
      "174\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "199\n",
      "173\n",
      "102\n",
      "195\n",
      "120\n",
      "120\n",
      "161\n",
      "160\n",
      "146\n",
      "144\n",
      "164\n",
      "185\n",
      "198\n",
      "178\n",
      "206\n",
      "206\n",
      "194\n",
      "185\n",
      "167\n",
      "191\n",
      "185\n",
      "163\n",
      "116\n",
      "113\n",
      "185\n",
      "161\n",
      "186\n",
      "171\n",
      "181\n",
      "189\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "137\n",
      "184\n",
      "181\n",
      "188\n",
      "203\n",
      "164\n",
      "191\n",
      "138\n",
      "206\n",
      "182\n",
      "204\n",
      "206\n",
      "176\n",
      "177\n",
      "159\n",
      "151\n",
      "152\n",
      "151\n",
      "206\n",
      "204\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "194\n",
      "146\n",
      "121\n",
      "206\n",
      "206\n",
      "206\n",
      "189\n",
      "128\n",
      "156\n",
      "198\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "182\n",
      "161\n",
      "48\n",
      "72\n",
      "131\n",
      "75\n",
      "100\n",
      "121\n",
      "129\n",
      "118\n",
      "134\n",
      "142\n",
      "142\n",
      "172\n",
      "172\n",
      "179\n",
      "179\n",
      "206\n",
      "206\n",
      "179\n",
      "183\n",
      "132\n",
      "193\n",
      "206\n",
      "206\n",
      "188\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "200\n",
      "206\n",
      "178\n",
      "202\n",
      "206\n",
      "181\n",
      "181\n",
      "202\n",
      "202\n",
      "161\n",
      "155\n",
      "169\n",
      "166\n",
      "193\n",
      "206\n",
      "201\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "189\n",
      "206\n",
      "166\n",
      "192\n",
      "190\n",
      "154\n",
      "154\n",
      "171\n",
      "181\n",
      "178\n",
      "196\n",
      "196\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "171\n",
      "174\n",
      "185\n",
      "184\n",
      "187\n",
      "197\n",
      "197\n",
      "206\n",
      "132\n",
      "107\n",
      "100\n",
      "100\n",
      "86\n",
      "102\n",
      "127\n",
      "127\n",
      "161\n",
      "176\n",
      "132\n",
      "161\n",
      "101\n",
      "197\n",
      "161\n",
      "166\n",
      "166\n",
      "165\n",
      "165\n",
      "113\n",
      "105\n",
      "145\n",
      "172\n",
      "186\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "197\n",
      "185\n",
      "174\n",
      "160\n",
      "199\n",
      "196\n",
      "201\n",
      "176\n",
      "206\n",
      "206\n",
      "185\n",
      "206\n",
      "206\n",
      "206\n",
      "186\n",
      "204\n",
      "172\n",
      "140\n",
      "152\n",
      "179\n",
      "159\n",
      "152\n",
      "164\n",
      "163\n",
      "175\n",
      "163\n",
      "205\n",
      "205\n",
      "206\n",
      "205\n",
      "205\n",
      "205\n",
      "192\n",
      "138\n",
      "172\n",
      "163\n",
      "173\n",
      "195\n",
      "201\n",
      "204\n",
      "168\n",
      "206\n",
      "160\n",
      "160\n",
      "160\n",
      "160\n",
      "190\n",
      "165\n",
      "108\n",
      "121\n",
      "138\n",
      "139\n",
      "138\n",
      "166\n",
      "151\n",
      "151\n",
      "150\n",
      "159\n",
      "164\n",
      "164\n",
      "176\n",
      "174\n",
      "186\n",
      "186\n",
      "196\n",
      "196\n",
      "198\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "171\n",
      "203\n",
      "195\n",
      "206\n",
      "206\n",
      "206\n",
      "191\n",
      "177\n",
      "164\n",
      "129\n",
      "184\n",
      "143\n",
      "187\n",
      "169\n",
      "169\n",
      "159\n",
      "179\n",
      "169\n",
      "169\n",
      "191\n",
      "202\n",
      "103\n",
      "70\n",
      "163\n",
      "161\n",
      "116\n",
      "137\n",
      "165\n",
      "161\n",
      "179\n",
      "188\n",
      "198\n",
      "169\n",
      "157\n",
      "170\n",
      "183\n",
      "191\n",
      "206\n",
      "206\n",
      "199\n",
      "160\n",
      "164\n",
      "160\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "180\n",
      "175\n",
      "171\n",
      "122\n",
      "161\n",
      "154\n",
      "194\n",
      "194\n",
      "203\n",
      "203\n",
      "203\n",
      "203\n",
      "0\n",
      "165\n",
      "127\n",
      "179\n",
      "179\n",
      "179\n",
      "185\n",
      "200\n",
      "201\n",
      "198\n",
      "198\n",
      "203\n",
      "198\n",
      "198\n",
      "198\n",
      "205\n",
      "142\n",
      "150\n",
      "147\n",
      "133\n",
      "162\n",
      "202\n",
      "183\n",
      "129\n",
      "187\n",
      "190\n",
      "204\n",
      "120\n",
      "120\n",
      "142\n",
      "146\n",
      "160\n",
      "184\n",
      "187\n",
      "191\n",
      "200\n",
      "161\n",
      "199\n",
      "148\n",
      "193\n",
      "206\n",
      "206\n",
      "54\n",
      "54\n",
      "54\n",
      "54\n",
      "126\n",
      "173\n",
      "173\n",
      "187\n",
      "178\n",
      "198\n",
      "189\n",
      "180\n",
      "162\n",
      "202\n",
      "197\n",
      "189\n",
      "184\n",
      "201\n",
      "167\n",
      "191\n",
      "171\n",
      "193\n",
      "167\n",
      "104\n",
      "161\n",
      "136\n",
      "162\n",
      "103\n",
      "136\n",
      "108\n",
      "182\n",
      "160\n",
      "176\n",
      "178\n",
      "185\n",
      "161\n",
      "179\n",
      "122\n",
      "185\n",
      "133\n",
      "162\n",
      "184\n",
      "162\n",
      "179\n",
      "186\n",
      "146\n",
      "160\n",
      "150\n",
      "197\n",
      "161\n",
      "187\n",
      "160\n",
      "156\n",
      "186\n",
      "161\n",
      "185\n",
      "162\n",
      "164\n",
      "184\n",
      "165\n",
      "186\n",
      "185\n",
      "174\n",
      "197\n",
      "176\n",
      "185\n",
      "180\n",
      "184\n",
      "183\n",
      "189\n",
      "189\n",
      "193\n",
      "193\n",
      "198\n",
      "198\n",
      "200\n",
      "201\n",
      "204\n",
      "204\n",
      "166\n",
      "161\n",
      "150\n",
      "109\n",
      "164\n",
      "157\n",
      "181\n",
      "195\n",
      "179\n",
      "206\n",
      "206\n",
      "185\n",
      "124\n",
      "150\n",
      "161\n",
      "191\n",
      "196\n",
      "166\n",
      "194\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "161\n",
      "191\n",
      "179\n",
      "159\n",
      "171\n",
      "159\n",
      "185\n",
      "135\n",
      "193\n",
      "205\n",
      "205\n",
      "206\n",
      "160\n",
      "203\n",
      "206\n",
      "205\n",
      "170\n",
      "185\n",
      "117\n",
      "126\n",
      "126\n",
      "190\n",
      "206\n",
      "168\n",
      "169\n",
      "167\n",
      "195\n",
      "187\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "189\n",
      "206\n",
      "141\n",
      "206\n",
      "165\n",
      "178\n",
      "174\n",
      "206\n",
      "206\n",
      "206\n",
      "193\n",
      "202\n",
      "179\n",
      "179\n",
      "179\n",
      "176\n",
      "189\n",
      "162\n",
      "109\n",
      "142\n",
      "171\n",
      "178\n",
      "194\n",
      "124\n",
      "170\n",
      "170\n",
      "183\n",
      "184\n",
      "200\n",
      "190\n",
      "190\n",
      "198\n",
      "190\n",
      "100\n",
      "103\n",
      "123\n",
      "123\n",
      "140\n",
      "141\n",
      "103\n",
      "102\n",
      "162\n",
      "180\n",
      "73\n",
      "136\n",
      "61\n",
      "150\n",
      "103\n",
      "161\n",
      "66\n",
      "160\n",
      "107\n",
      "78\n",
      "163\n",
      "102\n",
      "149\n",
      "166\n",
      "187\n",
      "101\n",
      "166\n",
      "189\n",
      "101\n",
      "169\n",
      "192\n",
      "102\n",
      "164\n",
      "198\n",
      "168\n",
      "111\n",
      "192\n",
      "165\n",
      "163\n",
      "189\n",
      "122\n",
      "166\n",
      "141\n",
      "126\n",
      "170\n",
      "188\n",
      "142\n",
      "162\n",
      "160\n",
      "149\n",
      "175\n",
      "137\n",
      "179\n",
      "187\n",
      "161\n",
      "168\n",
      "175\n",
      "161\n",
      "137\n",
      "185\n",
      "103\n",
      "174\n",
      "138\n",
      "170\n",
      "166\n",
      "150\n",
      "102\n",
      "131\n",
      "202\n",
      "192\n",
      "122\n",
      "163\n",
      "119\n",
      "198\n",
      "202\n",
      "126\n",
      "167\n",
      "106\n",
      "166\n",
      "0\n",
      "104\n",
      "102\n",
      "162\n",
      "185\n",
      "137\n",
      "100\n",
      "160\n",
      "166\n",
      "106\n",
      "191\n",
      "185\n",
      "159\n",
      "165\n",
      "185\n",
      "160\n",
      "135\n",
      "187\n",
      "112\n",
      "161\n",
      "174\n",
      "183\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "188\n",
      "175\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "164\n",
      "164\n",
      "182\n",
      "182\n",
      "182\n",
      "194\n",
      "194\n",
      "181\n",
      "188\n",
      "204\n",
      "179\n",
      "148\n",
      "189\n",
      "165\n",
      "188\n",
      "148\n",
      "161\n",
      "150\n",
      "153\n",
      "161\n",
      "156\n",
      "184\n",
      "161\n",
      "163\n",
      "163\n",
      "185\n",
      "166\n",
      "167\n",
      "185\n",
      "171\n",
      "174\n",
      "174\n",
      "185\n",
      "177\n",
      "198\n",
      "185\n",
      "184\n",
      "186\n",
      "186\n",
      "189\n",
      "189\n",
      "191\n",
      "196\n",
      "198\n",
      "198\n",
      "201\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "151\n",
      "195\n",
      "195\n",
      "202\n",
      "178\n",
      "191\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "192\n",
      "192\n",
      "193\n",
      "192\n",
      "201\n",
      "206\n",
      "163\n",
      "191\n",
      "115\n",
      "188\n",
      "190\n",
      "200\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "205\n",
      "205\n",
      "205\n",
      "206\n",
      "146\n",
      "161\n",
      "161\n",
      "171\n",
      "102\n",
      "184\n",
      "101\n",
      "101\n",
      "160\n",
      "186\n",
      "143\n",
      "143\n",
      "189\n",
      "149\n",
      "144\n",
      "141\n",
      "200\n",
      "117\n",
      "109\n",
      "83\n",
      "165\n",
      "10\n",
      "102\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "161\n",
      "100\n",
      "53\n",
      "101\n",
      "161\n",
      "62\n",
      "102\n",
      "100\n",
      "102\n",
      "108\n",
      "114\n",
      "162\n",
      "126\n",
      "139\n",
      "161\n",
      "159\n",
      "159\n",
      "189\n",
      "165\n",
      "174\n",
      "176\n",
      "176\n",
      "199\n",
      "186\n",
      "199\n",
      "163\n",
      "163\n",
      "161\n",
      "101\n",
      "163\n",
      "161\n",
      "45\n",
      "160\n",
      "171\n",
      "172\n",
      "185\n",
      "190\n",
      "165\n",
      "161\n",
      "159\n",
      "150\n",
      "154\n",
      "154\n",
      "202\n",
      "125\n",
      "187\n",
      "197\n",
      "200\n",
      "185\n",
      "99\n",
      "158\n",
      "161\n",
      "179\n",
      "160\n",
      "194\n",
      "176\n",
      "205\n",
      "197\n",
      "206\n",
      "194\n",
      "155\n",
      "178\n",
      "176\n",
      "198\n",
      "128\n",
      "206\n",
      "181\n",
      "182\n",
      "203\n",
      "187\n",
      "146\n",
      "206\n",
      "156\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "190\n",
      "183\n",
      "188\n",
      "187\n",
      "167\n",
      "167\n",
      "176\n",
      "167\n",
      "169\n",
      "174\n",
      "183\n",
      "206\n",
      "195\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "189\n",
      "74\n",
      "123\n",
      "81\n",
      "112\n",
      "187\n",
      "161\n",
      "132\n",
      "132\n",
      "160\n",
      "160\n",
      "160\n",
      "173\n",
      "194\n",
      "206\n",
      "183\n",
      "157\n",
      "191\n",
      "180\n",
      "202\n",
      "166\n",
      "206\n",
      "203\n",
      "203\n",
      "156\n",
      "153\n",
      "164\n",
      "162\n",
      "176\n",
      "180\n",
      "193\n",
      "206\n",
      "185\n",
      "168\n",
      "168\n",
      "168\n",
      "168\n",
      "205\n",
      "194\n",
      "187\n",
      "100\n",
      "101\n",
      "193\n",
      "174\n",
      "170\n",
      "130\n",
      "188\n",
      "205\n",
      "205\n",
      "182\n",
      "130\n",
      "161\n",
      "104\n",
      "182\n",
      "165\n",
      "172\n",
      "153\n",
      "155\n",
      "185\n",
      "197\n",
      "203\n",
      "186\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "170\n",
      "161\n",
      "198\n",
      "198\n",
      "203\n",
      "203\n",
      "121\n",
      "137\n",
      "133\n",
      "181\n",
      "177\n",
      "170\n",
      "190\n",
      "195\n",
      "197\n",
      "161\n",
      "186\n",
      "160\n",
      "161\n",
      "160\n",
      "179\n",
      "187\n",
      "110\n",
      "89\n",
      "97\n",
      "191\n",
      "143\n",
      "170\n",
      "170\n",
      "161\n",
      "102\n",
      "161\n",
      "114\n",
      "160\n",
      "126\n",
      "158\n",
      "188\n",
      "157\n",
      "182\n",
      "185\n",
      "161\n",
      "160\n",
      "143\n",
      "199\n",
      "166\n",
      "149\n",
      "179\n",
      "169\n",
      "153\n",
      "153\n",
      "185\n",
      "172\n",
      "156\n",
      "175\n",
      "159\n",
      "181\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "185\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "188\n",
      "188\n",
      "164\n",
      "191\n",
      "191\n",
      "184\n",
      "165\n",
      "161\n",
      "161\n",
      "105\n",
      "137\n",
      "69\n",
      "114\n",
      "120\n",
      "120\n",
      "147\n",
      "145\n",
      "150\n",
      "150\n",
      "159\n",
      "171\n",
      "170\n",
      "174\n",
      "182\n",
      "180\n",
      "186\n",
      "186\n",
      "194\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "166\n",
      "130\n",
      "114\n",
      "57\n",
      "175\n",
      "113\n",
      "166\n",
      "125\n",
      "115\n",
      "194\n",
      "196\n",
      "205\n",
      "204\n",
      "204\n",
      "181\n",
      "170\n",
      "198\n",
      "190\n",
      "183\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "183\n",
      "191\n",
      "197\n",
      "203\n",
      "205\n",
      "206\n",
      "116\n",
      "134\n",
      "178\n",
      "178\n",
      "118\n",
      "105\n",
      "125\n",
      "161\n",
      "146\n",
      "146\n",
      "176\n",
      "176\n",
      "185\n",
      "185\n",
      "205\n",
      "199\n",
      "162\n",
      "164\n",
      "169\n",
      "190\n",
      "204\n",
      "206\n",
      "206\n",
      "184\n",
      "186\n",
      "164\n",
      "182\n",
      "190\n",
      "194\n",
      "199\n",
      "169\n",
      "167\n",
      "145\n",
      "165\n",
      "201\n",
      "206\n",
      "206\n",
      "189\n",
      "206\n",
      "164\n",
      "200\n",
      "189\n",
      "194\n",
      "187\n",
      "204\n",
      "202\n",
      "192\n",
      "192\n",
      "201\n",
      "201\n",
      "192\n",
      "205\n",
      "192\n",
      "192\n",
      "206\n",
      "206\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "205\n",
      "189\n",
      "189\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "143\n",
      "187\n",
      "206\n",
      "142\n",
      "122\n",
      "139\n",
      "171\n",
      "206\n",
      "193\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "175\n",
      "150\n",
      "194\n",
      "136\n",
      "185\n",
      "185\n",
      "195\n",
      "180\n",
      "120\n",
      "110\n",
      "171\n",
      "128\n",
      "125\n",
      "126\n",
      "178\n",
      "162\n",
      "156\n",
      "161\n",
      "166\n",
      "166\n",
      "182\n",
      "178\n",
      "178\n",
      "181\n",
      "178\n",
      "191\n",
      "206\n",
      "206\n",
      "168\n",
      "164\n",
      "160\n",
      "181\n",
      "194\n",
      "193\n",
      "193\n",
      "199\n",
      "15\n",
      "91\n",
      "138\n",
      "160\n",
      "142\n",
      "170\n",
      "137\n",
      "105\n",
      "4\n",
      "177\n",
      "105\n",
      "105\n",
      "163\n",
      "189\n",
      "167\n",
      "197\n",
      "204\n",
      "206\n",
      "118\n",
      "201\n",
      "148\n",
      "119\n",
      "121\n",
      "149\n",
      "132\n",
      "140\n",
      "161\n",
      "173\n",
      "163\n",
      "163\n",
      "177\n",
      "174\n",
      "204\n",
      "202\n",
      "202\n",
      "202\n",
      "202\n",
      "202\n",
      "160\n",
      "184\n",
      "206\n",
      "175\n",
      "195\n",
      "170\n",
      "171\n",
      "162\n",
      "162\n",
      "161\n",
      "188\n",
      "161\n",
      "168\n",
      "152\n",
      "156\n",
      "160\n",
      "161\n",
      "161\n",
      "168\n",
      "171\n",
      "176\n",
      "183\n",
      "183\n",
      "199\n",
      "184\n",
      "201\n",
      "195\n",
      "149\n",
      "198\n",
      "111\n",
      "174\n",
      "164\n",
      "81\n",
      "160\n",
      "150\n",
      "106\n",
      "117\n",
      "87\n",
      "88\n",
      "122\n",
      "112\n",
      "143\n",
      "143\n",
      "155\n",
      "155\n",
      "154\n",
      "170\n",
      "169\n",
      "180\n",
      "200\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "188\n",
      "195\n",
      "161\n",
      "101\n",
      "150\n",
      "132\n",
      "122\n",
      "109\n",
      "146\n",
      "157\n",
      "153\n",
      "178\n",
      "189\n",
      "201\n",
      "198\n",
      "191\n",
      "175\n",
      "193\n",
      "171\n",
      "138\n",
      "199\n",
      "185\n",
      "186\n",
      "185\n",
      "198\n",
      "186\n",
      "171\n",
      "166\n",
      "105\n",
      "192\n",
      "161\n",
      "77\n",
      "138\n",
      "186\n",
      "161\n",
      "101\n",
      "101\n",
      "161\n",
      "136\n",
      "100\n",
      "160\n",
      "100\n",
      "101\n",
      "160\n",
      "101\n",
      "162\n",
      "70\n",
      "105\n",
      "160\n",
      "157\n",
      "102\n",
      "161\n",
      "104\n",
      "104\n",
      "99\n",
      "160\n",
      "162\n",
      "107\n",
      "162\n",
      "108\n",
      "110\n",
      "114\n",
      "122\n",
      "164\n",
      "126\n",
      "129\n",
      "166\n",
      "133\n",
      "138\n",
      "138\n",
      "142\n",
      "146\n",
      "149\n",
      "161\n",
      "150\n",
      "154\n",
      "164\n",
      "156\n",
      "158\n",
      "160\n",
      "163\n",
      "164\n",
      "166\n",
      "166\n",
      "166\n",
      "168\n",
      "172\n",
      "163\n",
      "138\n",
      "102\n",
      "121\n",
      "186\n",
      "185\n",
      "189\n",
      "177\n",
      "158\n",
      "206\n",
      "206\n",
      "206\n",
      "156\n",
      "124\n",
      "174\n",
      "159\n",
      "156\n",
      "156\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "102\n",
      "187\n",
      "164\n",
      "192\n",
      "192\n",
      "182\n",
      "187\n",
      "113\n",
      "162\n",
      "163\n",
      "173\n",
      "103\n",
      "160\n",
      "139\n",
      "187\n",
      "205\n",
      "141\n",
      "201\n",
      "201\n",
      "201\n",
      "188\n",
      "180\n",
      "189\n",
      "159\n",
      "144\n",
      "153\n",
      "132\n",
      "122\n",
      "136\n",
      "160\n",
      "199\n",
      "182\n",
      "116\n",
      "0\n",
      "160\n",
      "160\n",
      "162\n",
      "184\n",
      "104\n",
      "101\n",
      "164\n",
      "186\n",
      "162\n",
      "164\n",
      "164\n",
      "172\n",
      "190\n",
      "151\n",
      "206\n",
      "171\n",
      "170\n",
      "206\n",
      "206\n",
      "206\n",
      "195\n",
      "161\n",
      "105\n",
      "162\n",
      "202\n",
      "194\n",
      "158\n",
      "189\n",
      "202\n",
      "196\n",
      "101\n",
      "102\n",
      "61\n",
      "109\n",
      "164\n",
      "195\n",
      "201\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "151\n",
      "185\n",
      "174\n",
      "161\n",
      "152\n",
      "154\n",
      "206\n",
      "152\n",
      "151\n",
      "151\n",
      "151\n",
      "151\n",
      "151\n",
      "175\n",
      "151\n",
      "151\n",
      "151\n",
      "151\n",
      "152\n",
      "165\n",
      "206\n",
      "204\n",
      "206\n",
      "187\n",
      "163\n",
      "151\n",
      "151\n",
      "151\n",
      "151\n",
      "181\n",
      "187\n",
      "187\n",
      "189\n",
      "179\n",
      "189\n",
      "189\n",
      "122\n",
      "150\n",
      "192\n",
      "203\n",
      "194\n",
      "125\n",
      "126\n",
      "132\n",
      "122\n",
      "156\n",
      "156\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "131\n",
      "137\n",
      "181\n",
      "131\n",
      "169\n",
      "157\n",
      "157\n",
      "157\n",
      "162\n",
      "162\n",
      "168\n",
      "167\n",
      "173\n",
      "189\n",
      "187\n",
      "187\n",
      "187\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "173\n",
      "146\n",
      "172\n",
      "130\n",
      "160\n",
      "1\n",
      "116\n",
      "104\n",
      "103\n",
      "100\n",
      "101\n",
      "79\n",
      "161\n",
      "159\n",
      "149\n",
      "163\n",
      "117\n",
      "132\n",
      "133\n",
      "189\n",
      "165\n",
      "137\n",
      "138\n",
      "147\n",
      "165\n",
      "162\n",
      "198\n",
      "170\n",
      "171\n",
      "174\n",
      "180\n",
      "180\n",
      "180\n",
      "198\n",
      "198\n",
      "150\n",
      "203\n",
      "193\n",
      "159\n",
      "135\n",
      "146\n",
      "146\n",
      "138\n",
      "121\n",
      "123\n",
      "161\n",
      "188\n",
      "147\n",
      "147\n",
      "147\n",
      "175\n",
      "162\n",
      "160\n",
      "150\n",
      "150\n",
      "160\n",
      "150\n",
      "181\n",
      "181\n",
      "206\n",
      "162\n",
      "166\n",
      "199\n",
      "199\n",
      "199\n",
      "134\n",
      "168\n",
      "176\n",
      "190\n",
      "198\n",
      "206\n",
      "206\n",
      "193\n",
      "206\n",
      "204\n",
      "204\n",
      "204\n",
      "154\n",
      "152\n",
      "194\n",
      "201\n",
      "153\n",
      "206\n",
      "203\n",
      "179\n",
      "157\n",
      "156\n",
      "181\n",
      "201\n",
      "201\n",
      "200\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "179\n",
      "206\n",
      "189\n",
      "128\n",
      "164\n",
      "134\n",
      "162\n",
      "157\n",
      "161\n",
      "190\n",
      "160\n",
      "164\n",
      "174\n",
      "198\n",
      "191\n",
      "191\n",
      "191\n",
      "190\n",
      "109\n",
      "164\n",
      "200\n",
      "196\n",
      "206\n",
      "186\n",
      "206\n",
      "186\n",
      "186\n",
      "186\n",
      "186\n",
      "206\n",
      "206\n",
      "161\n",
      "119\n",
      "174\n",
      "203\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "185\n",
      "151\n",
      "159\n",
      "168\n",
      "183\n",
      "202\n",
      "206\n",
      "185\n",
      "109\n",
      "56\n",
      "104\n",
      "188\n",
      "162\n",
      "151\n",
      "152\n",
      "179\n",
      "183\n",
      "181\n",
      "201\n",
      "199\n",
      "199\n",
      "199\n",
      "178\n",
      "181\n",
      "192\n",
      "203\n",
      "206\n",
      "199\n",
      "196\n",
      "114\n",
      "95\n",
      "133\n",
      "173\n",
      "188\n",
      "187\n",
      "205\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "62\n",
      "71\n",
      "176\n",
      "110\n",
      "163\n",
      "121\n",
      "136\n",
      "157\n",
      "157\n",
      "157\n",
      "169\n",
      "167\n",
      "167\n",
      "171\n",
      "166\n",
      "184\n",
      "168\n",
      "178\n",
      "132\n",
      "166\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "191\n",
      "206\n",
      "187\n",
      "198\n",
      "175\n",
      "172\n",
      "201\n",
      "126\n",
      "182\n",
      "104\n",
      "162\n",
      "159\n",
      "101\n",
      "150\n",
      "112\n",
      "117\n",
      "117\n",
      "165\n",
      "134\n",
      "158\n",
      "158\n",
      "165\n",
      "166\n",
      "177\n",
      "177\n",
      "201\n",
      "201\n",
      "160\n",
      "135\n",
      "158\n",
      "187\n",
      "206\n",
      "167\n",
      "182\n",
      "167\n",
      "179\n",
      "168\n",
      "204\n",
      "204\n",
      "147\n",
      "167\n",
      "147\n",
      "151\n",
      "195\n",
      "178\n",
      "206\n",
      "198\n",
      "180\n",
      "127\n",
      "126\n",
      "177\n",
      "206\n",
      "162\n",
      "169\n",
      "185\n",
      "206\n",
      "206\n",
      "169\n",
      "174\n",
      "150\n",
      "120\n",
      "141\n",
      "135\n",
      "189\n",
      "148\n",
      "169\n",
      "191\n",
      "200\n",
      "159\n",
      "173\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "183\n",
      "142\n",
      "148\n",
      "185\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "144\n",
      "158\n",
      "186\n",
      "196\n",
      "206\n",
      "206\n",
      "186\n",
      "186\n",
      "186\n",
      "206\n",
      "171\n",
      "155\n",
      "179\n",
      "172\n",
      "161\n",
      "168\n",
      "168\n",
      "115\n",
      "115\n",
      "8\n",
      "163\n",
      "100\n",
      "62\n",
      "184\n",
      "195\n",
      "195\n",
      "186\n",
      "124\n",
      "155\n",
      "155\n",
      "167\n",
      "180\n",
      "112\n",
      "169\n",
      "112\n",
      "146\n",
      "146\n",
      "146\n",
      "192\n",
      "162\n",
      "202\n",
      "203\n",
      "202\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "184\n",
      "202\n",
      "203\n",
      "138\n",
      "179\n",
      "161\n",
      "161\n",
      "110\n",
      "153\n",
      "143\n",
      "146\n",
      "158\n",
      "194\n",
      "194\n",
      "188\n",
      "198\n",
      "199\n",
      "199\n",
      "199\n",
      "199\n",
      "200\n",
      "137\n",
      "164\n",
      "184\n",
      "162\n",
      "162\n",
      "167\n",
      "167\n",
      "189\n",
      "196\n",
      "196\n",
      "186\n",
      "192\n",
      "191\n",
      "178\n",
      "104\n",
      "101\n",
      "104\n",
      "110\n",
      "142\n",
      "166\n",
      "202\n",
      "203\n",
      "203\n",
      "203\n",
      "130\n",
      "140\n",
      "181\n",
      "172\n",
      "172\n",
      "187\n",
      "187\n",
      "202\n",
      "202\n",
      "189\n",
      "161\n",
      "162\n",
      "118\n",
      "170\n",
      "185\n",
      "163\n",
      "179\n",
      "206\n",
      "206\n",
      "200\n",
      "162\n",
      "182\n",
      "181\n",
      "181\n",
      "119\n",
      "203\n",
      "104\n",
      "104\n",
      "162\n",
      "108\n",
      "108\n",
      "137\n",
      "147\n",
      "151\n",
      "156\n",
      "199\n",
      "161\n",
      "170\n",
      "184\n",
      "195\n",
      "195\n",
      "195\n",
      "202\n",
      "204\n",
      "202\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "149\n",
      "162\n",
      "185\n",
      "185\n",
      "165\n",
      "160\n",
      "164\n",
      "129\n",
      "202\n",
      "180\n",
      "195\n",
      "206\n",
      "206\n",
      "130\n",
      "148\n",
      "170\n",
      "164\n",
      "155\n",
      "183\n",
      "206\n",
      "109\n",
      "171\n",
      "122\n",
      "167\n",
      "130\n",
      "129\n",
      "163\n",
      "140\n",
      "154\n",
      "177\n",
      "162\n",
      "157\n",
      "157\n",
      "157\n",
      "185\n",
      "163\n",
      "206\n",
      "175\n",
      "164\n",
      "194\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "203\n",
      "185\n",
      "183\n",
      "187\n",
      "168\n",
      "187\n",
      "141\n",
      "146\n",
      "141\n",
      "142\n",
      "202\n",
      "202\n",
      "177\n",
      "197\n",
      "161\n",
      "187\n",
      "162\n",
      "161\n",
      "175\n",
      "188\n",
      "156\n",
      "159\n",
      "200\n",
      "165\n",
      "167\n",
      "169\n",
      "197\n",
      "189\n",
      "191\n",
      "195\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "129\n",
      "117\n",
      "106\n",
      "22\n",
      "35\n",
      "102\n",
      "104\n",
      "106\n",
      "180\n",
      "113\n",
      "97\n",
      "135\n",
      "121\n",
      "160\n",
      "124\n",
      "136\n",
      "141\n",
      "185\n",
      "146\n",
      "152\n",
      "152\n",
      "160\n",
      "165\n",
      "194\n",
      "194\n",
      "195\n",
      "153\n",
      "188\n",
      "125\n",
      "82\n",
      "98\n",
      "104\n",
      "144\n",
      "124\n",
      "134\n",
      "137\n",
      "138\n",
      "187\n",
      "165\n",
      "151\n",
      "151\n",
      "151\n",
      "151\n",
      "187\n",
      "168\n",
      "159\n",
      "159\n",
      "159\n",
      "160\n",
      "184\n",
      "175\n",
      "169\n",
      "169\n",
      "169\n",
      "169\n",
      "187\n",
      "174\n",
      "174\n",
      "174\n",
      "174\n",
      "174\n",
      "203\n",
      "203\n",
      "189\n",
      "168\n",
      "199\n",
      "199\n",
      "204\n",
      "204\n",
      "206\n",
      "206\n",
      "184\n",
      "190\n",
      "190\n",
      "185\n",
      "206\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "146\n",
      "169\n",
      "101\n",
      "126\n",
      "170\n",
      "117\n",
      "117\n",
      "188\n",
      "167\n",
      "167\n",
      "167\n",
      "206\n",
      "194\n",
      "184\n",
      "138\n",
      "191\n",
      "198\n",
      "190\n",
      "199\n",
      "171\n",
      "171\n",
      "171\n",
      "199\n",
      "172\n",
      "171\n",
      "171\n",
      "181\n",
      "206\n",
      "206\n",
      "154\n",
      "166\n",
      "197\n",
      "176\n",
      "189\n",
      "195\n",
      "167\n",
      "183\n",
      "157\n",
      "143\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "127\n",
      "193\n",
      "123\n",
      "186\n",
      "186\n",
      "180\n",
      "198\n",
      "198\n",
      "198\n",
      "206\n",
      "206\n",
      "162\n",
      "124\n",
      "155\n",
      "177\n",
      "198\n",
      "198\n",
      "194\n",
      "169\n",
      "136\n",
      "136\n",
      "185\n",
      "164\n",
      "198\n",
      "198\n",
      "204\n",
      "194\n",
      "174\n",
      "174\n",
      "174\n",
      "206\n",
      "144\n",
      "131\n",
      "154\n",
      "205\n",
      "206\n",
      "147\n",
      "192\n",
      "151\n",
      "166\n",
      "176\n",
      "179\n",
      "199\n",
      "201\n",
      "201\n",
      "206\n",
      "206\n",
      "206\n",
      "122\n",
      "182\n",
      "181\n",
      "109\n",
      "112\n",
      "194\n",
      "206\n",
      "193\n",
      "200\n",
      "166\n",
      "107\n",
      "142\n",
      "142\n",
      "194\n",
      "206\n",
      "206\n",
      "162\n",
      "206\n",
      "126\n",
      "126\n",
      "161\n",
      "206\n",
      "206\n",
      "192\n",
      "206\n",
      "178\n",
      "51\n",
      "155\n",
      "201\n",
      "206\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "192\n",
      "206\n",
      "175\n",
      "203\n",
      "182\n",
      "197\n",
      "197\n",
      "197\n",
      "197\n",
      "197\n",
      "197\n",
      "197\n",
      "198\n",
      "206\n",
      "162\n",
      "146\n",
      "182\n",
      "199\n",
      "182\n",
      "139\n",
      "151\n",
      "163\n",
      "163\n",
      "184\n",
      "201\n",
      "171\n",
      "190\n",
      "195\n",
      "195\n",
      "202\n",
      "179\n",
      "188\n",
      "199\n",
      "168\n",
      "160\n",
      "172\n",
      "148\n",
      "164\n",
      "164\n",
      "164\n",
      "164\n",
      "164\n",
      "134\n",
      "146\n",
      "145\n",
      "159\n",
      "184\n",
      "140\n",
      "172\n",
      "200\n",
      "100\n",
      "86\n",
      "116\n",
      "116\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "193\n",
      "130\n",
      "132\n",
      "172\n",
      "150\n",
      "198\n",
      "198\n",
      "180\n",
      "201\n",
      "197\n",
      "199\n",
      "196\n",
      "188\n",
      "196\n",
      "156\n",
      "158\n",
      "197\n",
      "189\n",
      "206\n",
      "177\n",
      "200\n",
      "200\n",
      "200\n",
      "201\n",
      "204\n",
      "174\n",
      "141\n",
      "160\n",
      "171\n",
      "172\n",
      "206\n",
      "206\n",
      "201\n",
      "205\n",
      "205\n",
      "183\n",
      "101\n",
      "89\n",
      "97\n",
      "99\n",
      "119\n",
      "129\n",
      "135\n",
      "178\n",
      "178\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "117\n",
      "104\n",
      "125\n",
      "136\n",
      "148\n",
      "148\n",
      "185\n",
      "181\n",
      "182\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "198\n",
      "107\n",
      "164\n",
      "143\n",
      "176\n",
      "90\n",
      "163\n",
      "126\n",
      "116\n",
      "130\n",
      "155\n",
      "162\n",
      "166\n",
      "190\n",
      "190\n",
      "187\n",
      "192\n",
      "192\n",
      "193\n",
      "201\n",
      "206\n",
      "206\n",
      "204\n",
      "182\n",
      "206\n",
      "161\n",
      "162\n",
      "182\n",
      "201\n",
      "180\n",
      "119\n",
      "34\n",
      "188\n",
      "109\n",
      "165\n",
      "132\n",
      "130\n",
      "153\n",
      "173\n",
      "185\n",
      "185\n",
      "185\n",
      "183\n",
      "183\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "185\n",
      "196\n",
      "185\n",
      "202\n",
      "101\n",
      "98\n",
      "132\n",
      "133\n",
      "189\n",
      "189\n",
      "200\n",
      "206\n",
      "206\n",
      "170\n",
      "171\n",
      "190\n",
      "200\n",
      "200\n",
      "165\n",
      "181\n",
      "190\n",
      "202\n",
      "172\n",
      "187\n",
      "183\n",
      "116\n",
      "190\n",
      "144\n",
      "118\n",
      "163\n",
      "198\n",
      "162\n",
      "126\n",
      "156\n",
      "137\n",
      "172\n",
      "172\n",
      "181\n",
      "181\n",
      "182\n",
      "191\n",
      "191\n",
      "204\n",
      "167\n",
      "199\n",
      "202\n",
      "170\n",
      "176\n",
      "186\n",
      "204\n",
      "178\n",
      "119\n",
      "165\n",
      "149\n",
      "164\n",
      "100\n",
      "103\n",
      "117\n",
      "147\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "171\n",
      "171\n",
      "164\n",
      "164\n",
      "164\n",
      "200\n",
      "200\n",
      "114\n",
      "157\n",
      "181\n",
      "180\n",
      "191\n",
      "191\n",
      "200\n",
      "205\n",
      "205\n",
      "205\n",
      "148\n",
      "148\n",
      "160\n",
      "177\n",
      "206\n",
      "200\n",
      "194\n",
      "122\n",
      "163\n",
      "134\n",
      "184\n",
      "104\n",
      "69\n",
      "172\n",
      "109\n",
      "83\n",
      "130\n",
      "113\n",
      "172\n",
      "123\n",
      "133\n",
      "143\n",
      "143\n",
      "143\n",
      "172\n",
      "153\n",
      "153\n",
      "153\n",
      "153\n",
      "153\n",
      "153\n",
      "153\n",
      "167\n",
      "167\n",
      "170\n",
      "169\n",
      "167\n",
      "184\n",
      "184\n",
      "184\n",
      "186\n",
      "184\n",
      "111\n",
      "171\n",
      "206\n",
      "206\n",
      "173\n",
      "162\n",
      "184\n",
      "155\n",
      "164\n",
      "172\n",
      "138\n",
      "147\n",
      "125\n",
      "169\n",
      "179\n",
      "198\n",
      "204\n",
      "199\n",
      "163\n",
      "151\n",
      "133\n",
      "187\n",
      "33\n",
      "163\n",
      "188\n",
      "206\n",
      "179\n",
      "157\n",
      "206\n",
      "141\n",
      "178\n",
      "198\n",
      "201\n",
      "204\n",
      "161\n",
      "133\n",
      "172\n",
      "76\n",
      "186\n",
      "163\n",
      "162\n",
      "102\n",
      "149\n",
      "161\n",
      "104\n",
      "175\n",
      "105\n",
      "161\n",
      "116\n",
      "192\n",
      "161\n",
      "187\n",
      "202\n",
      "131\n",
      "166\n",
      "182\n",
      "177\n",
      "11\n",
      "111\n",
      "197\n",
      "167\n",
      "192\n",
      "189\n",
      "158\n",
      "171\n",
      "188\n",
      "193\n",
      "193\n",
      "168\n",
      "196\n",
      "197\n",
      "187\n",
      "189\n",
      "193\n",
      "195\n",
      "205\n",
      "179\n",
      "199\n",
      "178\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "202\n",
      "200\n",
      "206\n",
      "206\n",
      "181\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "184\n",
      "178\n",
      "185\n",
      "203\n",
      "203\n",
      "203\n",
      "148\n",
      "206\n",
      "155\n",
      "148\n",
      "117\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "171\n",
      "170\n",
      "198\n",
      "171\n",
      "190\n",
      "124\n",
      "161\n",
      "166\n",
      "86\n",
      "161\n",
      "75\n",
      "108\n",
      "87\n",
      "138\n",
      "148\n",
      "166\n",
      "185\n",
      "206\n",
      "185\n",
      "171\n",
      "133\n",
      "137\n",
      "202\n",
      "164\n",
      "160\n",
      "109\n",
      "122\n",
      "165\n",
      "164\n",
      "116\n",
      "98\n",
      "198\n",
      "112\n",
      "108\n",
      "168\n",
      "197\n",
      "121\n",
      "193\n",
      "126\n",
      "116\n",
      "195\n",
      "121\n",
      "134\n",
      "139\n",
      "148\n",
      "197\n",
      "190\n",
      "157\n",
      "156\n",
      "156\n",
      "178\n",
      "159\n",
      "163\n",
      "198\n",
      "180\n",
      "171\n",
      "171\n",
      "185\n",
      "177\n",
      "193\n",
      "183\n",
      "204\n",
      "204\n",
      "191\n",
      "196\n",
      "191\n",
      "152\n",
      "151\n",
      "120\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "163\n",
      "168\n",
      "183\n",
      "206\n",
      "194\n",
      "174\n",
      "150\n",
      "204\n",
      "200\n",
      "185\n",
      "206\n",
      "171\n",
      "206\n",
      "176\n",
      "206\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "172\n",
      "202\n",
      "203\n",
      "182\n",
      "152\n",
      "170\n",
      "197\n",
      "172\n",
      "194\n",
      "78\n",
      "101\n",
      "100\n",
      "119\n",
      "163\n",
      "161\n",
      "148\n",
      "178\n",
      "102\n",
      "101\n",
      "106\n",
      "170\n",
      "192\n",
      "104\n",
      "109\n",
      "95\n",
      "101\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "195\n",
      "198\n",
      "157\n",
      "137\n",
      "185\n",
      "167\n",
      "194\n",
      "170\n",
      "160\n",
      "161\n",
      "192\n",
      "203\n",
      "206\n",
      "177\n",
      "160\n",
      "186\n",
      "136\n",
      "133\n",
      "173\n",
      "185\n",
      "164\n",
      "184\n",
      "187\n",
      "183\n",
      "198\n",
      "184\n",
      "184\n",
      "190\n",
      "184\n",
      "176\n",
      "184\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "194\n",
      "176\n",
      "202\n",
      "189\n",
      "136\n",
      "166\n",
      "150\n",
      "162\n",
      "87\n",
      "113\n",
      "56\n",
      "200\n",
      "151\n",
      "126\n",
      "165\n",
      "203\n",
      "187\n",
      "134\n",
      "148\n",
      "187\n",
      "165\n",
      "188\n",
      "172\n",
      "194\n",
      "182\n",
      "183\n",
      "201\n",
      "178\n",
      "117\n",
      "99\n",
      "194\n",
      "174\n",
      "168\n",
      "105\n",
      "141\n",
      "179\n",
      "187\n",
      "187\n",
      "201\n",
      "169\n",
      "177\n",
      "188\n",
      "195\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "163\n",
      "163\n",
      "185\n",
      "190\n",
      "190\n",
      "193\n",
      "133\n",
      "124\n",
      "124\n",
      "164\n",
      "62\n",
      "73\n",
      "160\n",
      "108\n",
      "185\n",
      "155\n",
      "185\n",
      "167\n",
      "107\n",
      "108\n",
      "168\n",
      "118\n",
      "166\n",
      "142\n",
      "142\n",
      "163\n",
      "188\n",
      "188\n",
      "199\n",
      "168\n",
      "107\n",
      "161\n",
      "179\n",
      "201\n",
      "205\n",
      "189\n",
      "202\n",
      "202\n",
      "205\n",
      "186\n",
      "185\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "133\n",
      "164\n",
      "163\n",
      "173\n",
      "188\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "206\n",
      "197\n",
      "185\n",
      "203\n",
      "162\n",
      "155\n",
      "154\n",
      "154\n",
      "154\n",
      "198\n",
      "178\n",
      "178\n",
      "178\n",
      "197\n",
      "174\n",
      "187\n",
      "110\n",
      "161\n",
      "163\n",
      "190\n",
      "166\n",
      "200\n",
      "191\n",
      "206\n",
      "160\n",
      "119\n",
      "191\n",
      "172\n",
      "206\n",
      "206\n",
      "199\n",
      "168\n",
      "206\n",
      "171\n",
      "182\n",
      "205\n",
      "206\n",
      "206\n",
      "141\n",
      "193\n",
      "158\n",
      "160\n",
      "158\n",
      "159\n",
      "199\n",
      "206\n",
      "168\n",
      "202\n",
      "188\n",
      "161\n",
      "205\n",
      "161\n",
      "192\n",
      "163\n",
      "128\n",
      "147\n",
      "193\n",
      "114\n",
      "131\n",
      "186\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "112\n",
      "166\n",
      "160\n",
      "185\n",
      "161\n",
      "181\n",
      "193\n",
      "202\n",
      "200\n",
      "148\n",
      "145\n",
      "174\n",
      "106\n",
      "142\n",
      "106\n",
      "143\n",
      "119\n",
      "152\n",
      "167\n",
      "184\n",
      "190\n",
      "204\n",
      "112\n",
      "206\n",
      "203\n",
      "148\n",
      "137\n",
      "186\n",
      "155\n",
      "114\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "205\n",
      "205\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "196\n",
      "183\n",
      "206\n",
      "206\n",
      "205\n",
      "202\n",
      "200\n",
      "183\n",
      "199\n",
      "199\n",
      "202\n",
      "202\n",
      "202\n",
      "202\n",
      "171\n",
      "173\n",
      "182\n",
      "190\n",
      "177\n",
      "177\n",
      "134\n",
      "140\n",
      "161\n",
      "172\n",
      "187\n",
      "201\n",
      "184\n",
      "190\n",
      "190\n",
      "190\n",
      "172\n",
      "161\n",
      "157\n",
      "173\n",
      "173\n",
      "193\n",
      "193\n",
      "205\n",
      "205\n",
      "192\n",
      "199\n",
      "205\n",
      "206\n",
      "143\n",
      "156\n",
      "156\n",
      "191\n",
      "162\n",
      "162\n",
      "166\n",
      "166\n",
      "163\n",
      "188\n",
      "166\n",
      "201\n",
      "193\n",
      "166\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "187\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "190\n",
      "164\n",
      "197\n",
      "190\n",
      "169\n",
      "189\n",
      "177\n",
      "193\n",
      "202\n",
      "203\n",
      "204\n",
      "189\n",
      "172\n",
      "158\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "174\n",
      "160\n",
      "158\n",
      "157\n",
      "160\n",
      "187\n",
      "191\n",
      "199\n",
      "202\n",
      "205\n",
      "186\n",
      "186\n",
      "179\n",
      "178\n",
      "179\n",
      "178\n",
      "179\n",
      "203\n",
      "203\n",
      "205\n",
      "205\n",
      "205\n",
      "197\n",
      "206\n",
      "206\n",
      "196\n",
      "168\n",
      "199\n",
      "178\n",
      "170\n",
      "191\n",
      "206\n",
      "167\n",
      "203\n",
      "181\n",
      "167\n",
      "197\n",
      "199\n",
      "190\n",
      "167\n",
      "206\n",
      "167\n",
      "206\n",
      "178\n",
      "193\n",
      "161\n",
      "170\n",
      "197\n",
      "200\n",
      "197\n",
      "200\n",
      "205\n",
      "205\n",
      "206\n",
      "206\n",
      "179\n",
      "173\n",
      "205\n",
      "135\n",
      "69\n",
      "180\n",
      "206\n",
      "190\n",
      "149\n",
      "109\n",
      "130\n",
      "159\n",
      "153\n",
      "165\n",
      "181\n",
      "181\n",
      "173\n",
      "180\n",
      "160\n",
      "198\n",
      "191\n",
      "189\n",
      "189\n",
      "206\n",
      "206\n",
      "195\n",
      "202\n",
      "203\n",
      "155\n",
      "182\n",
      "179\n",
      "191\n",
      "203\n",
      "198\n",
      "198\n",
      "188\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "120\n",
      "103\n",
      "162\n",
      "112\n",
      "197\n",
      "197\n",
      "206\n",
      "206\n",
      "136\n",
      "202\n",
      "185\n",
      "107\n",
      "175\n",
      "186\n",
      "185\n",
      "190\n",
      "190\n",
      "195\n",
      "196\n",
      "202\n",
      "180\n",
      "206\n",
      "204\n",
      "187\n",
      "179\n",
      "185\n",
      "185\n",
      "185\n",
      "203\n",
      "198\n",
      "174\n",
      "189\n",
      "145\n",
      "157\n",
      "163\n",
      "177\n",
      "168\n",
      "189\n",
      "190\n",
      "186\n",
      "188\n",
      "200\n",
      "203\n",
      "187\n",
      "187\n",
      "187\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "148\n",
      "197\n",
      "129\n",
      "182\n",
      "197\n",
      "103\n",
      "98\n",
      "136\n",
      "192\n",
      "185\n",
      "160\n",
      "122\n",
      "143\n",
      "161\n",
      "185\n",
      "179\n",
      "197\n",
      "186\n",
      "186\n",
      "186\n",
      "186\n",
      "206\n",
      "206\n",
      "155\n",
      "156\n",
      "194\n",
      "194\n",
      "194\n",
      "201\n",
      "153\n",
      "156\n",
      "148\n",
      "185\n",
      "202\n",
      "206\n",
      "206\n",
      "201\n",
      "151\n",
      "134\n",
      "161\n",
      "165\n",
      "156\n",
      "185\n",
      "178\n",
      "178\n",
      "178\n",
      "178\n",
      "205\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "196\n",
      "202\n",
      "202\n",
      "191\n",
      "151\n",
      "187\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "167\n",
      "145\n",
      "142\n",
      "188\n",
      "194\n",
      "194\n",
      "202\n",
      "154\n",
      "200\n",
      "205\n",
      "195\n",
      "168\n",
      "158\n",
      "158\n",
      "159\n",
      "159\n",
      "197\n",
      "186\n",
      "185\n",
      "205\n",
      "206\n",
      "175\n",
      "188\n",
      "199\n",
      "67\n",
      "163\n",
      "107\n",
      "134\n",
      "134\n",
      "176\n",
      "187\n",
      "187\n",
      "187\n",
      "190\n",
      "192\n",
      "200\n",
      "200\n",
      "205\n",
      "203\n",
      "161\n",
      "162\n",
      "160\n",
      "164\n",
      "186\n",
      "166\n",
      "161\n",
      "189\n",
      "167\n",
      "167\n",
      "167\n",
      "167\n",
      "167\n",
      "178\n",
      "177\n",
      "169\n",
      "173\n",
      "173\n",
      "202\n",
      "202\n",
      "176\n",
      "130\n",
      "84\n",
      "111\n",
      "160\n",
      "187\n",
      "172\n",
      "105\n",
      "100\n",
      "76\n",
      "162\n",
      "164\n",
      "172\n",
      "184\n",
      "184\n",
      "186\n",
      "194\n",
      "182\n",
      "195\n",
      "206\n",
      "206\n",
      "178\n",
      "177\n",
      "205\n",
      "191\n",
      "187\n",
      "165\n",
      "190\n",
      "177\n",
      "206\n",
      "203\n",
      "206\n",
      "196\n",
      "193\n",
      "193\n",
      "193\n",
      "193\n",
      "199\n",
      "203\n",
      "182\n",
      "192\n",
      "192\n",
      "182\n",
      "206\n",
      "198\n",
      "182\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "160\n",
      "193\n",
      "124\n",
      "195\n",
      "196\n",
      "199\n",
      "161\n",
      "196\n",
      "165\n",
      "165\n",
      "124\n",
      "142\n",
      "164\n",
      "163\n",
      "173\n",
      "174\n",
      "195\n",
      "192\n",
      "195\n",
      "195\n",
      "201\n",
      "201\n",
      "201\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "187\n",
      "191\n",
      "137\n",
      "112\n",
      "167\n",
      "169\n",
      "130\n",
      "140\n",
      "149\n",
      "169\n",
      "157\n",
      "174\n",
      "166\n",
      "200\n",
      "198\n",
      "199\n",
      "183\n",
      "183\n",
      "183\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "188\n",
      "171\n",
      "179\n",
      "169\n",
      "139\n",
      "157\n",
      "178\n",
      "186\n",
      "198\n",
      "186\n",
      "202\n",
      "171\n",
      "206\n",
      "162\n",
      "194\n",
      "141\n",
      "159\n",
      "164\n",
      "189\n",
      "164\n",
      "164\n",
      "188\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "172\n",
      "164\n",
      "148\n",
      "184\n",
      "59\n",
      "113\n",
      "71\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "149\n",
      "176\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "101\n",
      "164\n",
      "160\n",
      "158\n",
      "166\n",
      "165\n",
      "173\n",
      "183\n",
      "199\n",
      "123\n",
      "141\n",
      "168\n",
      "191\n",
      "191\n",
      "173\n",
      "161\n",
      "206\n",
      "161\n",
      "109\n",
      "161\n",
      "130\n",
      "155\n",
      "150\n",
      "184\n",
      "206\n",
      "185\n",
      "161\n",
      "145\n",
      "145\n",
      "160\n",
      "156\n",
      "185\n",
      "169\n",
      "184\n",
      "200\n",
      "200\n",
      "198\n",
      "160\n",
      "158\n",
      "158\n",
      "164\n",
      "188\n",
      "167\n",
      "164\n",
      "179\n",
      "188\n",
      "188\n",
      "185\n",
      "109\n",
      "179\n",
      "206\n",
      "161\n",
      "186\n",
      "204\n",
      "115\n",
      "119\n",
      "191\n",
      "196\n",
      "206\n",
      "171\n",
      "206\n",
      "143\n",
      "129\n",
      "170\n",
      "189\n",
      "183\n",
      "197\n",
      "176\n",
      "193\n",
      "193\n",
      "193\n",
      "193\n",
      "107\n",
      "117\n",
      "147\n",
      "166\n",
      "183\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "129\n",
      "122\n",
      "166\n",
      "178\n",
      "108\n",
      "138\n",
      "161\n",
      "108\n",
      "106\n",
      "103\n",
      "82\n",
      "101\n",
      "164\n",
      "97\n",
      "113\n",
      "202\n",
      "129\n",
      "119\n",
      "170\n",
      "144\n",
      "165\n",
      "165\n",
      "183\n",
      "200\n",
      "161\n",
      "178\n",
      "178\n",
      "141\n",
      "199\n",
      "193\n",
      "190\n",
      "143\n",
      "153\n",
      "166\n",
      "161\n",
      "146\n",
      "185\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "166\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "181\n",
      "181\n",
      "154\n",
      "191\n",
      "202\n",
      "144\n",
      "185\n",
      "165\n",
      "171\n",
      "187\n",
      "205\n",
      "203\n",
      "188\n",
      "185\n",
      "158\n",
      "161\n",
      "163\n",
      "166\n",
      "206\n",
      "206\n",
      "187\n",
      "155\n",
      "202\n",
      "171\n",
      "140\n",
      "158\n",
      "180\n",
      "159\n",
      "168\n",
      "190\n",
      "190\n",
      "191\n",
      "161\n",
      "161\n",
      "160\n",
      "160\n",
      "178\n",
      "172\n",
      "172\n",
      "203\n",
      "203\n",
      "204\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "145\n",
      "201\n",
      "182\n",
      "179\n",
      "205\n",
      "197\n",
      "178\n",
      "145\n",
      "145\n",
      "172\n",
      "171\n",
      "183\n",
      "189\n",
      "200\n",
      "205\n",
      "156\n",
      "163\n",
      "184\n",
      "198\n",
      "156\n",
      "201\n",
      "160\n",
      "169\n",
      "194\n",
      "185\n",
      "115\n",
      "161\n",
      "121\n",
      "163\n",
      "164\n",
      "134\n",
      "185\n",
      "166\n",
      "137\n",
      "137\n",
      "160\n",
      "165\n",
      "170\n",
      "181\n",
      "181\n",
      "206\n",
      "161\n",
      "105\n",
      "185\n",
      "182\n",
      "167\n",
      "206\n",
      "186\n",
      "195\n",
      "177\n",
      "133\n",
      "185\n",
      "157\n",
      "180\n",
      "170\n",
      "182\n",
      "182\n",
      "183\n",
      "194\n",
      "194\n",
      "194\n",
      "200\n",
      "199\n",
      "205\n",
      "205\n",
      "205\n",
      "206\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "145\n",
      "119\n",
      "123\n",
      "120\n",
      "124\n",
      "124\n",
      "161\n",
      "147\n",
      "147\n",
      "165\n",
      "165\n",
      "171\n",
      "170\n",
      "170\n",
      "183\n",
      "183\n",
      "189\n",
      "195\n",
      "200\n",
      "204\n",
      "204\n",
      "159\n",
      "166\n",
      "204\n",
      "206\n",
      "157\n",
      "206\n",
      "157\n",
      "206\n",
      "203\n",
      "206\n",
      "157\n",
      "203\n",
      "167\n",
      "157\n",
      "157\n",
      "157\n",
      "158\n",
      "157\n",
      "198\n",
      "119\n",
      "157\n",
      "114\n",
      "129\n",
      "190\n",
      "159\n",
      "176\n",
      "186\n",
      "166\n",
      "187\n",
      "168\n",
      "168\n",
      "171\n",
      "193\n",
      "174\n",
      "195\n",
      "200\n",
      "193\n",
      "202\n",
      "198\n",
      "193\n",
      "200\n",
      "203\n",
      "170\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "161\n",
      "143\n",
      "177\n",
      "177\n",
      "203\n",
      "203\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "183\n",
      "183\n",
      "183\n",
      "192\n",
      "197\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "160\n",
      "124\n",
      "103\n",
      "78\n",
      "160\n",
      "94\n",
      "101\n",
      "187\n",
      "120\n",
      "118\n",
      "74\n",
      "105\n",
      "187\n",
      "135\n",
      "136\n",
      "139\n",
      "187\n",
      "197\n",
      "162\n",
      "199\n",
      "190\n",
      "190\n",
      "190\n",
      "195\n",
      "174\n",
      "195\n",
      "197\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "192\n",
      "199\n",
      "158\n",
      "161\n",
      "160\n",
      "192\n",
      "58\n",
      "105\n",
      "104\n",
      "99\n",
      "166\n",
      "198\n",
      "187\n",
      "199\n",
      "163\n",
      "169\n",
      "140\n",
      "206\n",
      "180\n",
      "180\n",
      "191\n",
      "119\n",
      "191\n",
      "191\n",
      "146\n",
      "182\n",
      "161\n",
      "175\n",
      "204\n",
      "205\n",
      "148\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "172\n",
      "186\n",
      "156\n",
      "135\n",
      "145\n",
      "178\n",
      "119\n",
      "172\n",
      "125\n",
      "119\n",
      "184\n",
      "168\n",
      "206\n",
      "206\n",
      "206\n",
      "146\n",
      "170\n",
      "100\n",
      "185\n",
      "119\n",
      "161\n",
      "145\n",
      "146\n",
      "145\n",
      "178\n",
      "179\n",
      "181\n",
      "194\n",
      "194\n",
      "199\n",
      "199\n",
      "206\n",
      "194\n",
      "194\n",
      "206\n",
      "195\n",
      "206\n",
      "155\n",
      "206\n",
      "194\n",
      "134\n",
      "161\n",
      "200\n",
      "144\n",
      "182\n",
      "169\n",
      "113\n",
      "164\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "141\n",
      "200\n",
      "182\n",
      "184\n",
      "188\n",
      "156\n",
      "119\n",
      "159\n",
      "108\n",
      "149\n",
      "138\n",
      "190\n",
      "96\n",
      "111\n",
      "167\n",
      "156\n",
      "159\n",
      "159\n",
      "163\n",
      "163\n",
      "173\n",
      "177\n",
      "177\n",
      "182\n",
      "191\n",
      "191\n",
      "191\n",
      "193\n",
      "193\n",
      "199\n",
      "193\n",
      "202\n",
      "199\n",
      "199\n",
      "199\n",
      "204\n",
      "204\n",
      "195\n",
      "206\n",
      "164\n",
      "174\n",
      "193\n",
      "170\n",
      "202\n",
      "202\n",
      "160\n",
      "174\n",
      "182\n",
      "203\n",
      "206\n",
      "169\n",
      "106\n",
      "66\n",
      "107\n",
      "167\n",
      "113\n",
      "181\n",
      "123\n",
      "171\n",
      "178\n",
      "184\n",
      "185\n",
      "184\n",
      "184\n",
      "194\n",
      "200\n",
      "200\n",
      "205\n",
      "204\n",
      "166\n",
      "184\n",
      "186\n",
      "162\n",
      "192\n",
      "162\n",
      "176\n",
      "157\n",
      "163\n",
      "154\n",
      "165\n",
      "171\n",
      "180\n",
      "182\n",
      "198\n",
      "203\n",
      "162\n",
      "161\n",
      "163\n",
      "185\n",
      "164\n",
      "184\n",
      "171\n",
      "170\n",
      "191\n",
      "167\n",
      "186\n",
      "106\n",
      "161\n",
      "115\n",
      "162\n",
      "182\n",
      "167\n",
      "146\n",
      "166\n",
      "165\n",
      "168\n",
      "175\n",
      "177\n",
      "189\n",
      "197\n",
      "198\n",
      "206\n",
      "206\n",
      "120\n",
      "120\n",
      "170\n",
      "163\n",
      "206\n",
      "191\n",
      "206\n",
      "199\n",
      "139\n",
      "128\n",
      "125\n",
      "107\n",
      "164\n",
      "102\n",
      "111\n",
      "77\n",
      "123\n",
      "101\n",
      "98\n",
      "124\n",
      "164\n",
      "125\n",
      "159\n",
      "178\n",
      "177\n",
      "177\n",
      "186\n",
      "185\n",
      "184\n",
      "185\n",
      "184\n",
      "199\n",
      "199\n",
      "199\n",
      "201\n",
      "199\n",
      "199\n",
      "182\n",
      "167\n",
      "100\n",
      "194\n",
      "162\n",
      "185\n",
      "161\n",
      "106\n",
      "103\n",
      "160\n",
      "105\n",
      "43\n",
      "164\n",
      "67\n",
      "161\n",
      "102\n",
      "68\n",
      "101\n",
      "171\n",
      "112\n",
      "116\n",
      "191\n",
      "164\n",
      "123\n",
      "123\n",
      "127\n",
      "127\n",
      "167\n",
      "151\n",
      "169\n",
      "157\n",
      "156\n",
      "156\n",
      "156\n",
      "169\n",
      "163\n",
      "173\n",
      "173\n",
      "176\n",
      "176\n",
      "192\n",
      "185\n",
      "183\n",
      "183\n",
      "195\n",
      "193\n",
      "191\n",
      "191\n",
      "197\n",
      "197\n",
      "197\n",
      "197\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "171\n",
      "203\n",
      "136\n",
      "179\n",
      "189\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "104\n",
      "1\n",
      "100\n",
      "161\n",
      "59\n",
      "107\n",
      "108\n",
      "161\n",
      "109\n",
      "152\n",
      "152\n",
      "170\n",
      "190\n",
      "200\n",
      "189\n",
      "198\n",
      "205\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "161\n",
      "114\n",
      "57\n",
      "127\n",
      "162\n",
      "68\n",
      "109\n",
      "111\n",
      "162\n",
      "78\n",
      "146\n",
      "134\n",
      "105\n",
      "121\n",
      "175\n",
      "189\n",
      "186\n",
      "139\n",
      "165\n",
      "111\n",
      "166\n",
      "124\n",
      "187\n",
      "146\n",
      "188\n",
      "171\n",
      "169\n",
      "134\n",
      "135\n",
      "134\n",
      "140\n",
      "140\n",
      "167\n",
      "165\n",
      "189\n",
      "171\n",
      "152\n",
      "152\n",
      "175\n",
      "147\n",
      "148\n",
      "157\n",
      "157\n",
      "157\n",
      "169\n",
      "168\n",
      "197\n",
      "182\n",
      "180\n",
      "179\n",
      "177\n",
      "177\n",
      "202\n",
      "176\n",
      "181\n",
      "186\n",
      "195\n",
      "199\n",
      "181\n",
      "123\n",
      "0\n",
      "107\n",
      "162\n",
      "108\n",
      "161\n",
      "101\n",
      "110\n",
      "38\n",
      "114\n",
      "100\n",
      "172\n",
      "159\n",
      "171\n",
      "205\n",
      "113\n",
      "107\n",
      "107\n",
      "107\n",
      "1\n",
      "102\n",
      "154\n",
      "199\n",
      "109\n",
      "206\n",
      "190\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "177\n",
      "180\n",
      "176\n",
      "203\n",
      "185\n",
      "198\n",
      "197\n",
      "167\n",
      "59\n",
      "103\n",
      "190\n",
      "174\n",
      "77\n",
      "129\n",
      "133\n",
      "140\n",
      "162\n",
      "172\n",
      "176\n",
      "182\n",
      "189\n",
      "196\n",
      "204\n",
      "175\n",
      "162\n",
      "161\n",
      "161\n",
      "161\n",
      "191\n",
      "183\n",
      "182\n",
      "206\n",
      "191\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "111\n",
      "173\n",
      "140\n",
      "153\n",
      "179\n",
      "206\n",
      "203\n",
      "203\n",
      "206\n",
      "204\n",
      "145\n",
      "172\n",
      "183\n",
      "206\n",
      "193\n",
      "200\n",
      "199\n",
      "199\n",
      "202\n",
      "202\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "90\n",
      "203\n",
      "136\n",
      "0\n",
      "173\n",
      "162\n",
      "107\n",
      "142\n",
      "164\n",
      "109\n",
      "167\n",
      "168\n",
      "37\n",
      "167\n",
      "110\n",
      "56\n",
      "102\n",
      "61\n",
      "172\n",
      "69\n",
      "172\n",
      "114\n",
      "182\n",
      "184\n",
      "92\n",
      "181\n",
      "128\n",
      "104\n",
      "193\n",
      "99\n",
      "130\n",
      "204\n",
      "105\n",
      "130\n",
      "130\n",
      "155\n",
      "141\n",
      "142\n",
      "188\n",
      "184\n",
      "184\n",
      "201\n",
      "191\n",
      "191\n",
      "191\n",
      "191\n",
      "202\n",
      "192\n",
      "201\n",
      "201\n",
      "201\n",
      "161\n",
      "148\n",
      "192\n",
      "192\n",
      "192\n",
      "191\n",
      "200\n",
      "172\n",
      "167\n",
      "161\n",
      "183\n",
      "178\n",
      "145\n",
      "139\n",
      "134\n",
      "145\n",
      "148\n",
      "141\n",
      "202\n",
      "178\n",
      "206\n",
      "128\n",
      "81\n",
      "161\n",
      "100\n",
      "196\n",
      "196\n",
      "130\n",
      "130\n",
      "148\n",
      "148\n",
      "206\n",
      "185\n",
      "190\n",
      "161\n",
      "115\n",
      "112\n",
      "129\n",
      "129\n",
      "165\n",
      "149\n",
      "167\n",
      "171\n",
      "179\n",
      "179\n",
      "188\n",
      "188\n",
      "192\n",
      "195\n",
      "195\n",
      "195\n",
      "202\n",
      "202\n",
      "177\n",
      "173\n",
      "176\n",
      "112\n",
      "166\n",
      "162\n",
      "100\n",
      "76\n",
      "101\n",
      "160\n",
      "100\n",
      "175\n",
      "77\n",
      "160\n",
      "31\n",
      "185\n",
      "161\n",
      "161\n",
      "164\n",
      "101\n",
      "190\n",
      "139\n",
      "139\n",
      "164\n",
      "165\n",
      "169\n",
      "171\n",
      "174\n",
      "126\n",
      "171\n",
      "163\n",
      "161\n",
      "106\n",
      "164\n",
      "190\n",
      "115\n",
      "161\n",
      "187\n",
      "162\n",
      "127\n",
      "189\n",
      "133\n",
      "136\n",
      "164\n",
      "139\n",
      "165\n",
      "187\n",
      "142\n",
      "146\n",
      "147\n",
      "190\n",
      "151\n",
      "153\n",
      "156\n",
      "163\n",
      "158\n",
      "160\n",
      "161\n",
      "167\n",
      "173\n",
      "205\n",
      "162\n",
      "100\n",
      "140\n",
      "100\n",
      "185\n",
      "180\n",
      "198\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "144\n",
      "174\n",
      "206\n",
      "206\n",
      "204\n",
      "186\n",
      "140\n",
      "140\n",
      "160\n",
      "171\n",
      "172\n",
      "190\n",
      "149\n",
      "206\n",
      "117\n",
      "181\n",
      "140\n",
      "161\n",
      "194\n",
      "181\n",
      "194\n",
      "194\n",
      "177\n",
      "177\n",
      "184\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "199\n",
      "199\n",
      "63\n",
      "181\n",
      "145\n",
      "140\n",
      "141\n",
      "206\n",
      "206\n",
      "192\n",
      "183\n",
      "184\n",
      "199\n",
      "160\n",
      "160\n",
      "184\n",
      "206\n",
      "206\n",
      "164\n",
      "131\n",
      "11\n",
      "202\n",
      "125\n",
      "143\n",
      "143\n",
      "151\n",
      "151\n",
      "151\n",
      "178\n",
      "187\n",
      "190\n",
      "129\n",
      "120\n",
      "122\n",
      "120\n",
      "121\n",
      "144\n",
      "136\n",
      "139\n",
      "139\n",
      "143\n",
      "144\n",
      "206\n",
      "199\n",
      "184\n",
      "202\n",
      "181\n",
      "145\n",
      "165\n",
      "162\n",
      "183\n",
      "203\n",
      "206\n",
      "206\n",
      "180\n",
      "180\n",
      "139\n",
      "161\n",
      "150\n",
      "150\n",
      "150\n",
      "175\n",
      "175\n",
      "188\n",
      "188\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "172\n",
      "186\n",
      "177\n",
      "180\n",
      "196\n",
      "124\n",
      "184\n",
      "199\n",
      "120\n",
      "197\n",
      "187\n",
      "154\n",
      "164\n",
      "191\n",
      "164\n",
      "178\n",
      "158\n",
      "137\n",
      "132\n",
      "137\n",
      "103\n",
      "161\n",
      "160\n",
      "100\n",
      "161\n",
      "160\n",
      "101\n",
      "89\n",
      "106\n",
      "161\n",
      "142\n",
      "154\n",
      "182\n",
      "206\n",
      "198\n",
      "198\n",
      "158\n",
      "202\n",
      "104\n",
      "107\n",
      "107\n",
      "139\n",
      "176\n",
      "206\n",
      "206\n",
      "194\n",
      "193\n",
      "202\n",
      "202\n",
      "188\n",
      "164\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "bond_list = []\n",
    "for i in range(final_data.shape[0]):\n",
    "    chunk = final_data[i,:,:]\n",
    "    chunk = chunk.transpose()\n",
    "    print(len(set(np.argwhere(np.isnan(chunk))[:,0])))\n",
    "    if len(set(np.argwhere(np.isnan(chunk))[:,0])) <100:\n",
    "        bond_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 75,\n",
       " 161,\n",
       " 428,\n",
       " 430,\n",
       " 431,\n",
       " 665,\n",
       " 668,\n",
       " 670,\n",
       " 708,\n",
       " 809,\n",
       " 813,\n",
       " 910,\n",
       " 980,\n",
       " 981,\n",
       " 1102,\n",
       " 1108,\n",
       " 1110,\n",
       " 1430,\n",
       " 1433,\n",
       " 1748,\n",
       " 1777,\n",
       " 1895,\n",
       " 2053,\n",
       " 2057,\n",
       " 2154,\n",
       " 2156,\n",
       " 2177,\n",
       " 2179,\n",
       " 2180,\n",
       " 2193,\n",
       " 2201,\n",
       " 2206,\n",
       " 2429,\n",
       " 2431,\n",
       " 2434,\n",
       " 2435,\n",
       " 2457,\n",
       " 2713,\n",
       " 2854,\n",
       " 2981,\n",
       " 3010,\n",
       " 3066,\n",
       " 3094,\n",
       " 3274,\n",
       " 3275,\n",
       " 3277,\n",
       " 3392,\n",
       " 3520,\n",
       " 3557,\n",
       " 3599,\n",
       " 3600,\n",
       " 3601,\n",
       " 3602,\n",
       " 3781,\n",
       " 3783,\n",
       " 3787,\n",
       " 3790,\n",
       " 3850,\n",
       " 4025,\n",
       " 4027,\n",
       " 4035,\n",
       " 4038,\n",
       " 4064,\n",
       " 4082,\n",
       " 4192,\n",
       " 4194,\n",
       " 4285,\n",
       " 4286,\n",
       " 4346,\n",
       " 4371,\n",
       " 4547,\n",
       " 4548,\n",
       " 4555,\n",
       " 4617,\n",
       " 4622,\n",
       " 4623,\n",
       " 4672,\n",
       " 4687,\n",
       " 4695,\n",
       " 4802,\n",
       " 4835,\n",
       " 4931,\n",
       " 4937,\n",
       " 5098,\n",
       " 5119,\n",
       " 5147,\n",
       " 5148,\n",
       " 5289,\n",
       " 5292,\n",
       " 5514,\n",
       " 5515,\n",
       " 5521,\n",
       " 5540,\n",
       " 5541,\n",
       " 5780,\n",
       " 5839,\n",
       " 5894,\n",
       " 5895,\n",
       " 5896,\n",
       " 5931,\n",
       " 5957,\n",
       " 5986,\n",
       " 6077,\n",
       " 6080,\n",
       " 6129,\n",
       " 6144,\n",
       " 6164,\n",
       " 6243,\n",
       " 6245,\n",
       " 6247,\n",
       " 6265,\n",
       " 6416,\n",
       " 6431,\n",
       " 6498,\n",
       " 6500,\n",
       " 6519,\n",
       " 6549,\n",
       " 6550,\n",
       " 6886,\n",
       " 7010,\n",
       " 7125,\n",
       " 7162,\n",
       " 7169,\n",
       " 7315,\n",
       " 7317,\n",
       " 7433,\n",
       " 7436,\n",
       " 7783,\n",
       " 7785,\n",
       " 7790,\n",
       " 7819,\n",
       " 7822,\n",
       " 7927,\n",
       " 7967,\n",
       " 8043,\n",
       " 8046,\n",
       " 8076,\n",
       " 8078,\n",
       " 8081,\n",
       " 8135,\n",
       " 8138,\n",
       " 8173,\n",
       " 8176,\n",
       " 8180,\n",
       " 8231,\n",
       " 8238,\n",
       " 8249,\n",
       " 8295,\n",
       " 8299,\n",
       " 8388,\n",
       " 8391,\n",
       " 8400,\n",
       " 8403,\n",
       " 8405,\n",
       " 8407,\n",
       " 8412,\n",
       " 8417,\n",
       " 8461,\n",
       " 8499,\n",
       " 8504,\n",
       " 8506,\n",
       " 8628,\n",
       " 8646,\n",
       " 8726]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       ...,\n",
       "       [ 0.44080858,  0.4553372 , -0.48838767, ...,  0.43345243,\n",
       "        -0.14716391,  0.0249102 ],\n",
       "       [ 0.44067607,  0.45523724, -0.48746643, ...,  0.43733214,\n",
       "        -0.14368845,  0.01880987],\n",
       "       [ 0.45191313,  0.46302999, -0.49534643, ...,  0.47569804,\n",
       "        -0.14115822, -0.0041575 ]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk = final_data[14,:,:].transpose()\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = max(set(np.argwhere(np.isnan(chunk))[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = chunk[m+1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOND_AGE',\n",
       " 'BOND_COUPON',\n",
       " 'BOND_FACE_VALUE',\n",
       " 'BP',\n",
       " 'DEBT_OVER_EBITDA',\n",
       " 'DURATION',\n",
       " 'EMOM_6M',\n",
       " 'EP',\n",
       " 'EQUITY_MKT_CAP',\n",
       " 'EQUITY_VOL',\n",
       " 'FIRM_TOTAL_DEBT',\n",
       " 'MOM_6M',\n",
       " 'MOM_6M_INDUSTRY_LEVEL',\n",
       " 'MOM_6M_INTERACTED_RATINGS',\n",
       " 'NEG_BOOK_LEVERAGE',\n",
       " 'NEG_MKT_LEVERAGE',\n",
       " 'NEG_VOL_OF_TURNOVER',\n",
       " 'OAS',\n",
       " 'OPERATING_LEVERAGE',\n",
       " 'PROFITABILITY',\n",
       " 'PROFITABILITY_5YR_CHANGE',\n",
       " 'RATING',\n",
       " 'SHUMWAY_D2D',\n",
       " 'SKEW',\n",
       " 'SPREAD_MOM_6M',\n",
       " 'SPREAD_PD_RATIO',\n",
       " 'TOTAL_VOL',\n",
       " 'VIX_BETA',\n",
       " 'VALUE_AT_RISK',\n",
       " 'CONSTANT']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['unique_charnames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BOND_AGE',\n",
       " 'BOND_COUPON',\n",
       " 'BOND_FACE_VALUE',\n",
       " 'BP',\n",
       " 'DEBT_OVER_EBITDA',\n",
       " 'DURATION',\n",
       " 'EMOM_6M',\n",
       " 'EP',\n",
       " 'EQUITY_MKT_CAP',\n",
       " 'EQUITY_VOL',\n",
       " 'FIRM_TOTAL_DEBT',\n",
       " 'MOM_6M',\n",
       " 'MOM_6M_INDUSTRY_LEVEL',\n",
       " 'MOM_6M_INTERACTED_RATINGS',\n",
       " 'NEG_BOOK_LEVERAGE',\n",
       " 'NEG_MKT_LEVERAGE',\n",
       " 'NEG_VOL_OF_TURNOVER',\n",
       " 'OAS',\n",
       " 'OPERATING_LEVERAGE',\n",
       " 'PROFITABILITY',\n",
       " 'PROFITABILITY_5YR_CHANGE',\n",
       " 'RATING',\n",
       " 'SHUMWAY_D2D',\n",
       " 'SKEW',\n",
       " 'SPREAD_MOM_6M',\n",
       " 'SPREAD_PD_RATIO',\n",
       " 'TOTAL_VOL',\n",
       " 'VIX_BETA',\n",
       " 'VALUE_AT_RISK',\n",
       " 'target']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = list(data_dict['unique_charnames'])\n",
    "c.pop()\n",
    "c.append('target')\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,columns = c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOND_AGE</th>\n",
       "      <th>BOND_COUPON</th>\n",
       "      <th>BOND_FACE_VALUE</th>\n",
       "      <th>BP</th>\n",
       "      <th>DEBT_OVER_EBITDA</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>EMOM_6M</th>\n",
       "      <th>EP</th>\n",
       "      <th>EQUITY_MKT_CAP</th>\n",
       "      <th>EQUITY_VOL</th>\n",
       "      <th>...</th>\n",
       "      <th>PROFITABILITY_5YR_CHANGE</th>\n",
       "      <th>RATING</th>\n",
       "      <th>SHUMWAY_D2D</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>SPREAD_MOM_6M</th>\n",
       "      <th>SPREAD_PD_RATIO</th>\n",
       "      <th>TOTAL_VOL</th>\n",
       "      <th>VIX_BETA</th>\n",
       "      <th>VALUE_AT_RISK</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.486449</td>\n",
       "      <td>0.160748</td>\n",
       "      <td>-0.308879</td>\n",
       "      <td>-0.058879</td>\n",
       "      <td>-0.454206</td>\n",
       "      <td>0.418692</td>\n",
       "      <td>-0.443925</td>\n",
       "      <td>0.342844</td>\n",
       "      <td>-0.144694</td>\n",
       "      <td>0.257944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044554</td>\n",
       "      <td>-0.044049</td>\n",
       "      <td>-0.076977</td>\n",
       "      <td>-0.446729</td>\n",
       "      <td>-0.333645</td>\n",
       "      <td>0.311215</td>\n",
       "      <td>0.226168</td>\n",
       "      <td>-0.005607</td>\n",
       "      <td>-0.404673</td>\n",
       "      <td>-0.058665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.450226</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>-0.304525</td>\n",
       "      <td>-0.067421</td>\n",
       "      <td>-0.453846</td>\n",
       "      <td>0.404977</td>\n",
       "      <td>-0.360633</td>\n",
       "      <td>0.355072</td>\n",
       "      <td>-0.134798</td>\n",
       "      <td>0.333182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046196</td>\n",
       "      <td>-0.043764</td>\n",
       "      <td>-0.202899</td>\n",
       "      <td>-0.442081</td>\n",
       "      <td>-0.319005</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.345249</td>\n",
       "      <td>-0.100905</td>\n",
       "      <td>-0.462896</td>\n",
       "      <td>0.051323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.425598</td>\n",
       "      <td>0.158990</td>\n",
       "      <td>-0.298494</td>\n",
       "      <td>-0.112932</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>0.410540</td>\n",
       "      <td>-0.260850</td>\n",
       "      <td>0.161348</td>\n",
       "      <td>-0.101950</td>\n",
       "      <td>0.251107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117021</td>\n",
       "      <td>-0.049046</td>\n",
       "      <td>-0.079787</td>\n",
       "      <td>-0.322852</td>\n",
       "      <td>-0.171391</td>\n",
       "      <td>0.349424</td>\n",
       "      <td>0.431798</td>\n",
       "      <td>0.401683</td>\n",
       "      <td>-0.477857</td>\n",
       "      <td>-0.029083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.401632</td>\n",
       "      <td>0.167526</td>\n",
       "      <td>-0.297680</td>\n",
       "      <td>-0.091065</td>\n",
       "      <td>-0.426976</td>\n",
       "      <td>0.408076</td>\n",
       "      <td>0.128007</td>\n",
       "      <td>0.165808</td>\n",
       "      <td>-0.101381</td>\n",
       "      <td>0.223368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121668</td>\n",
       "      <td>-0.084589</td>\n",
       "      <td>-0.149892</td>\n",
       "      <td>-0.286942</td>\n",
       "      <td>-0.219072</td>\n",
       "      <td>0.348797</td>\n",
       "      <td>0.438144</td>\n",
       "      <td>0.471649</td>\n",
       "      <td>-0.480241</td>\n",
       "      <td>0.010738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.385211</td>\n",
       "      <td>0.173259</td>\n",
       "      <td>-0.299656</td>\n",
       "      <td>-0.077816</td>\n",
       "      <td>-0.429493</td>\n",
       "      <td>0.407997</td>\n",
       "      <td>0.079174</td>\n",
       "      <td>0.155202</td>\n",
       "      <td>-0.098967</td>\n",
       "      <td>0.105331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120482</td>\n",
       "      <td>-0.091986</td>\n",
       "      <td>-0.126345</td>\n",
       "      <td>-0.291917</td>\n",
       "      <td>-0.223990</td>\n",
       "      <td>0.345228</td>\n",
       "      <td>0.444970</td>\n",
       "      <td>0.464746</td>\n",
       "      <td>-0.478504</td>\n",
       "      <td>0.012394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.441405</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>-0.492218</td>\n",
       "      <td>0.319676</td>\n",
       "      <td>-0.442270</td>\n",
       "      <td>0.276913</td>\n",
       "      <td>-0.241189</td>\n",
       "      <td>0.271243</td>\n",
       "      <td>-0.123450</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028686</td>\n",
       "      <td>-0.168835</td>\n",
       "      <td>0.148466</td>\n",
       "      <td>-0.165370</td>\n",
       "      <td>0.118677</td>\n",
       "      <td>0.404021</td>\n",
       "      <td>0.431690</td>\n",
       "      <td>0.472330</td>\n",
       "      <td>-0.173584</td>\n",
       "      <td>0.037795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.441229</td>\n",
       "      <td>0.456098</td>\n",
       "      <td>-0.491574</td>\n",
       "      <td>0.334110</td>\n",
       "      <td>-0.445221</td>\n",
       "      <td>0.264523</td>\n",
       "      <td>-0.270903</td>\n",
       "      <td>0.314774</td>\n",
       "      <td>-0.126004</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015656</td>\n",
       "      <td>-0.185066</td>\n",
       "      <td>0.138199</td>\n",
       "      <td>-0.170953</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>0.375388</td>\n",
       "      <td>0.421508</td>\n",
       "      <td>0.437916</td>\n",
       "      <td>-0.155876</td>\n",
       "      <td>-0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.440809</td>\n",
       "      <td>0.455337</td>\n",
       "      <td>-0.488388</td>\n",
       "      <td>0.340295</td>\n",
       "      <td>-0.444606</td>\n",
       "      <td>0.253461</td>\n",
       "      <td>-0.255640</td>\n",
       "      <td>0.327525</td>\n",
       "      <td>-0.137385</td>\n",
       "      <td>0.090259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008607</td>\n",
       "      <td>-0.190289</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>-0.141804</td>\n",
       "      <td>-0.203886</td>\n",
       "      <td>0.413801</td>\n",
       "      <td>0.417374</td>\n",
       "      <td>0.433452</td>\n",
       "      <td>-0.147164</td>\n",
       "      <td>0.024910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.440676</td>\n",
       "      <td>0.455237</td>\n",
       "      <td>-0.487466</td>\n",
       "      <td>0.260018</td>\n",
       "      <td>-0.396799</td>\n",
       "      <td>0.252014</td>\n",
       "      <td>-0.308596</td>\n",
       "      <td>0.354232</td>\n",
       "      <td>-0.165465</td>\n",
       "      <td>-0.026186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012539</td>\n",
       "      <td>-0.194001</td>\n",
       "      <td>0.088670</td>\n",
       "      <td>-0.150850</td>\n",
       "      <td>-0.341092</td>\n",
       "      <td>0.421218</td>\n",
       "      <td>0.420322</td>\n",
       "      <td>0.437332</td>\n",
       "      <td>-0.143688</td>\n",
       "      <td>0.018810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.451913</td>\n",
       "      <td>0.463030</td>\n",
       "      <td>-0.495346</td>\n",
       "      <td>0.257435</td>\n",
       "      <td>-0.399948</td>\n",
       "      <td>0.263702</td>\n",
       "      <td>-0.258728</td>\n",
       "      <td>0.367822</td>\n",
       "      <td>-0.163544</td>\n",
       "      <td>-0.067477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008795</td>\n",
       "      <td>-0.210171</td>\n",
       "      <td>0.109876</td>\n",
       "      <td>-0.151499</td>\n",
       "      <td>-0.408997</td>\n",
       "      <td>0.406412</td>\n",
       "      <td>0.415719</td>\n",
       "      <td>0.475698</td>\n",
       "      <td>-0.141158</td>\n",
       "      <td>-0.004157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BOND_AGE  BOND_COUPON  BOND_FACE_VALUE        BP  DEBT_OVER_EBITDA  \\\n",
       "0   -0.486449     0.160748        -0.308879 -0.058879         -0.454206   \n",
       "1   -0.450226     0.161538        -0.304525 -0.067421         -0.453846   \n",
       "2   -0.425598     0.158990        -0.298494 -0.112932         -0.425598   \n",
       "3   -0.401632     0.167526        -0.297680 -0.091065         -0.426976   \n",
       "4   -0.385211     0.173259        -0.299656 -0.077816         -0.429493   \n",
       "..        ...          ...              ...       ...               ...   \n",
       "104  0.441405     0.455901        -0.492218  0.319676         -0.442270   \n",
       "105  0.441229     0.456098        -0.491574  0.334110         -0.445221   \n",
       "106  0.440809     0.455337        -0.488388  0.340295         -0.444606   \n",
       "107  0.440676     0.455237        -0.487466  0.260018         -0.396799   \n",
       "108  0.451913     0.463030        -0.495346  0.257435         -0.399948   \n",
       "\n",
       "     DURATION   EMOM_6M        EP  EQUITY_MKT_CAP  EQUITY_VOL  ...  \\\n",
       "0    0.418692 -0.443925  0.342844       -0.144694    0.257944  ...   \n",
       "1    0.404977 -0.360633  0.355072       -0.134798    0.333182  ...   \n",
       "2    0.410540 -0.260850  0.161348       -0.101950    0.251107  ...   \n",
       "3    0.408076  0.128007  0.165808       -0.101381    0.223368  ...   \n",
       "4    0.407997  0.079174  0.155202       -0.098967    0.105331  ...   \n",
       "..        ...       ...       ...             ...         ...  ...   \n",
       "104  0.276913 -0.241189  0.271243       -0.123450    0.044099  ...   \n",
       "105  0.264523 -0.270903  0.314774       -0.126004    0.068545  ...   \n",
       "106  0.253461 -0.255640  0.327525       -0.137385    0.090259  ...   \n",
       "107  0.252014 -0.308596  0.354232       -0.165465   -0.026186  ...   \n",
       "108  0.263702 -0.258728  0.367822       -0.163544   -0.067477  ...   \n",
       "\n",
       "     PROFITABILITY_5YR_CHANGE    RATING  SHUMWAY_D2D      SKEW  SPREAD_MOM_6M  \\\n",
       "0                   -0.044554 -0.044049    -0.076977 -0.446729      -0.333645   \n",
       "1                   -0.046196 -0.043764    -0.202899 -0.442081      -0.319005   \n",
       "2                   -0.117021 -0.049046    -0.079787 -0.322852      -0.171391   \n",
       "3                   -0.121668 -0.084589    -0.149892 -0.286942      -0.219072   \n",
       "4                   -0.120482 -0.091986    -0.126345 -0.291917      -0.223990   \n",
       "..                        ...       ...          ...       ...            ...   \n",
       "104                 -0.028686 -0.168835     0.148466 -0.165370       0.118677   \n",
       "105                 -0.015656 -0.185066     0.138199 -0.170953       0.139468   \n",
       "106                 -0.008607 -0.190289     0.086369 -0.141804      -0.203886   \n",
       "107                 -0.012539 -0.194001     0.088670 -0.150850      -0.341092   \n",
       "108                 -0.008795 -0.210171     0.109876 -0.151499      -0.408997   \n",
       "\n",
       "     SPREAD_PD_RATIO  TOTAL_VOL  VIX_BETA  VALUE_AT_RISK    target  \n",
       "0           0.311215   0.226168 -0.005607      -0.404673 -0.058665  \n",
       "1           0.347059   0.345249 -0.100905      -0.462896  0.051323  \n",
       "2           0.349424   0.431798  0.401683      -0.477857 -0.029083  \n",
       "3           0.348797   0.438144  0.471649      -0.480241  0.010738  \n",
       "4           0.345228   0.444970  0.464746      -0.478504  0.012394  \n",
       "..               ...        ...       ...            ...       ...  \n",
       "104         0.404021   0.431690  0.472330      -0.173584  0.037795  \n",
       "105         0.375388   0.421508  0.437916      -0.155876 -0.018100  \n",
       "106         0.413801   0.417374  0.433452      -0.147164  0.024910  \n",
       "107         0.421218   0.420322  0.437332      -0.143688  0.018810  \n",
       "108         0.406412   0.415719  0.475698      -0.141158 -0.004157  \n",
       "\n",
       "[109 rows x 30 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from RNN import RNN\n",
    "#from CNN import CNN\n",
    "from Transformer import Transformer\n",
    "\n",
    "from utils import series_to_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 30)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "look_back = 8\n",
    "n_features = df.shape[1] - 1\n",
    "\n",
    "# Walk-forward data split to avoid data leakage\n",
    "X_train, y_train, X_test, y_test, scale_X = series_to_supervised(df, train_size=0.7, n_in=look_back, n_out=7, target_column='target', dropnan=True, scale_X=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 232)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train_reshaped = X_train.values.reshape((-1,look_back,n_features))\n",
    "X_test_reshaped = X_test.values.reshape((-1,look_back,n_features))\n",
    "\n",
    "y_train_reshaped = y_train.values\n",
    "y_test_reshaped = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 8, 29)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 8, 29)       58          ['input_6[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 8, 29)       121885      ['layer_normalization_40[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 8, 29)        0           ['multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 8, 29)       0           ['dropout_45[0][0]',             \n",
      " ambda)                                                           'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 8, 4)         120         ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 8, 4)         0           ['conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 8, 29)        145         ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 8, 29)       0           ['conv1d_41[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 8, 29)       121885      ['layer_normalization_42[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 8, 29)        0           ['multi_head_attention_21[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 8, 29)       0           ['dropout_47[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 8, 4)         120         ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 8, 4)         0           ['conv1d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 8, 29)        145         ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 8, 29)       0           ['conv1d_43[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 8, 29)       121885      ['layer_normalization_44[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 8, 29)        0           ['multi_head_attention_22[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 8, 29)       0           ['dropout_49[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 8, 4)         120         ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 8, 4)         0           ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 8, 29)        145         ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 8, 29)       0           ['conv1d_45[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 8, 29)       121885      ['layer_normalization_46[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 8, 29)        0           ['multi_head_attention_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 8, 29)       0           ['dropout_51[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 8, 29)       58          ['tf.__operators__.add_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 8, 4)         120         ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 8, 4)         0           ['conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 8, 29)        145         ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 8, 29)       0           ['conv1d_47[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 8)           0           ['tf.__operators__.add_47[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          1152        ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 7)            903         ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 491,119\n",
      "Trainable params: 491,119\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "1/2 [==============>...............] - ETA: 6s - loss: 0.2726 - rmse: 0.5221 - mae: 0.4319 - smape: 65.3674 - coeff_determination: -19.1104WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.27178, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 7s 217ms/step - loss: 0.2718 - rmse: 0.5088 - mae: 0.4322 - smape: 65.6030 - coeff_determination: -284.4030\n",
      "Epoch 2/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2437 - rmse: 0.4936 - mae: 0.3998 - smape: 63.3756 - coeff_determination: -17.5205WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 2: loss improved from 0.27178 to 0.24280, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.2428 - rmse: 0.4786 - mae: 0.3990 - smape: 63.4214 - coeff_determination: -14.1138\n",
      "Epoch 3/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1934 - rmse: 0.4398 - mae: 0.3644 - smape: 64.7335 - coeff_determination: -13.7290WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 3: loss improved from 0.24280 to 0.19422, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.1942 - rmse: 0.4550 - mae: 0.3645 - smape: 64.8102 - coeff_determination: -12.1495\n",
      "Epoch 4/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1695 - rmse: 0.4117 - mae: 0.3484 - smape: 67.2617 - coeff_determination: -11.4215WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 4: loss improved from 0.19422 to 0.16929, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 0.1693 - rmse: 0.4074 - mae: 0.3489 - smape: 67.1858 - coeff_determination: -351.0509\n",
      "Epoch 5/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1651 - rmse: 0.4063 - mae: 0.3583 - smape: 72.6323 - coeff_determination: -11.2303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 5: loss improved from 0.16929 to 0.16514, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.1651 - rmse: 0.4073 - mae: 0.3587 - smape: 72.5582 - coeff_determination: -24.7741\n",
      "Epoch 6/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1568 - rmse: 0.3960 - mae: 0.3616 - smape: 78.6199 - coeff_determination: -10.6227WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 6: loss improved from 0.16514 to 0.15953, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1595 - rmse: 0.4462 - mae: 0.3644 - smape: 78.6308 - coeff_determination: -161.2517\n",
      "Epoch 7/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1520 - rmse: 0.3898 - mae: 0.3584 - smape: 81.7855 - coeff_determination: -10.3271WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 7: loss improved from 0.15953 to 0.15417, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1542 - rmse: 0.4319 - mae: 0.3617 - smape: 82.0514 - coeff_determination: -183.8333\n",
      "Epoch 8/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1552 - rmse: 0.3939 - mae: 0.3674 - smape: 85.4107 - coeff_determination: -10.5906WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 8: loss improved from 0.15417 to 0.15416, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1542 - rmse: 0.3719 - mae: 0.3663 - smape: 85.3839 - coeff_determination: -10.4362\n",
      "Epoch 9/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1507 - rmse: 0.3881 - mae: 0.3595 - smape: 84.2405 - coeff_determination: -10.2564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 9: loss improved from 0.15416 to 0.15334, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.1533 - rmse: 0.4387 - mae: 0.3634 - smape: 84.6463 - coeff_determination: -255.4584\n",
      "Epoch 10/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1542 - rmse: 0.3927 - mae: 0.3706 - smape: 87.2683 - coeff_determination: -10.5946WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 10: loss did not improve from 0.15334\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1540 - rmse: 0.3882 - mae: 0.3705 - smape: 87.3494 - coeff_determination: -10.0233\n",
      "Epoch 11/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1508 - rmse: 0.3884 - mae: 0.3658 - smape: 86.7200 - coeff_determination: -10.3262WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 11: loss improved from 0.15334 to 0.15328, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1533 - rmse: 0.4346 - mae: 0.3690 - smape: 86.7118 - coeff_determination: -6258.6011\n",
      "Epoch 12/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1553 - rmse: 0.3941 - mae: 0.3704 - smape: 87.4207 - coeff_determination: -10.4887WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 12: loss did not improve from 0.15328\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1560 - rmse: 0.4085 - mae: 0.3718 - smape: 87.4839 - coeff_determination: -27.3420\n",
      "Epoch 13/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1516 - rmse: 0.3893 - mae: 0.3663 - smape: 85.8267 - coeff_determination: -10.6207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 13: loss improved from 0.15328 to 0.14875, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.1487 - rmse: 0.3158 - mae: 0.3621 - smape: 85.6833 - coeff_determination: -48.0290\n",
      "Epoch 14/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1466 - rmse: 0.3829 - mae: 0.3612 - smape: 85.1660 - coeff_determination: -10.0327WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 14: loss improved from 0.14875 to 0.14397, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1440 - rmse: 0.3126 - mae: 0.3569 - smape: 84.6724 - coeff_determination: -250.6130\n",
      "Epoch 15/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1425 - rmse: 0.3775 - mae: 0.3516 - smape: 81.3193 - coeff_determination: -9.6743WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 15: loss improved from 0.14397 to 0.14322, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 0.1432 - rmse: 0.3917 - mae: 0.3524 - smape: 81.3437 - coeff_determination: -10.9432\n",
      "Epoch 16/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1399 - rmse: 0.3740 - mae: 0.3441 - smape: 78.1724 - coeff_determination: -9.4871WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 16: loss improved from 0.14322 to 0.14175, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.1417 - rmse: 0.4109 - mae: 0.3468 - smape: 78.1794 - coeff_determination: -17333.6289\n",
      "Epoch 17/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1364 - rmse: 0.3693 - mae: 0.3380 - smape: 75.9461 - coeff_determination: -9.1101WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 17: loss improved from 0.14175 to 0.13819, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1382 - rmse: 0.4061 - mae: 0.3408 - smape: 76.0697 - coeff_determination: -75.0401\n",
      "Epoch 18/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1335 - rmse: 0.3653 - mae: 0.3292 - smape: 72.7719 - coeff_determination: -8.9101WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 18: loss improved from 0.13819 to 0.13483, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1348 - rmse: 0.3941 - mae: 0.3316 - smape: 72.8470 - coeff_determination: -152.2517\n",
      "Epoch 19/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1349 - rmse: 0.3673 - mae: 0.3295 - smape: 72.3563 - coeff_determination: -8.9307WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 19: loss did not improve from 0.13483\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1355 - rmse: 0.3808 - mae: 0.3304 - smape: 72.2952 - coeff_determination: -20.5696\n",
      "Epoch 20/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1355 - rmse: 0.3681 - mae: 0.3287 - smape: 70.3384 - coeff_determination: -9.3667WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 20: loss did not improve from 0.13483\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1353 - rmse: 0.3638 - mae: 0.3280 - smape: 70.5018 - coeff_determination: -7.3419\n",
      "Epoch 21/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1383 - rmse: 0.3719 - mae: 0.3321 - smape: 71.3725 - coeff_determination: -9.5939WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 21: loss did not improve from 0.13483\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1376 - rmse: 0.3560 - mae: 0.3311 - smape: 71.4298 - coeff_determination: -7.0394\n",
      "Epoch 22/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1349 - rmse: 0.3672 - mae: 0.3303 - smape: 71.8252 - coeff_determination: -9.3159WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 22: loss improved from 0.13483 to 0.13405, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.1340 - rmse: 0.3480 - mae: 0.3292 - smape: 71.9385 - coeff_determination: -6.7586\n",
      "Epoch 23/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1351 - rmse: 0.3676 - mae: 0.3244 - smape: 70.0141 - coeff_determination: -8.9038WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 23: loss did not improve from 0.13405\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1357 - rmse: 0.3798 - mae: 0.3257 - smape: 69.9834 - coeff_determination: -142.8651\n",
      "Epoch 24/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1292 - rmse: 0.3594 - mae: 0.3166 - smape: 68.7414 - coeff_determination: -8.6955WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 24: loss improved from 0.13405 to 0.13082, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.1308 - rmse: 0.3942 - mae: 0.3194 - smape: 68.7808 - coeff_determination: -869.7833\n",
      "Epoch 25/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1241 - rmse: 0.3522 - mae: 0.3101 - smape: 66.9013 - coeff_determination: -8.4827WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 25: loss improved from 0.13082 to 0.12298, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.1230 - rmse: 0.3250 - mae: 0.3083 - smape: 66.7289 - coeff_determination: -5.9122\n",
      "Epoch 26/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1358 - rmse: 0.3686 - mae: 0.3252 - smape: 69.6308 - coeff_determination: -9.2662WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 26: loss did not improve from 0.12298\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1348 - rmse: 0.3431 - mae: 0.3233 - smape: 69.1160 - coeff_determination: -7.2513\n",
      "Epoch 27/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1268 - rmse: 0.3561 - mae: 0.3068 - smape: 65.3991 - coeff_determination: -8.3971WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 27: loss did not improve from 0.12298\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1263 - rmse: 0.3448 - mae: 0.3065 - smape: 65.5709 - coeff_determination: -12.8448\n",
      "Epoch 28/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1337 - rmse: 0.3657 - mae: 0.3218 - smape: 69.6998 - coeff_determination: -8.8660WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 28: loss did not improve from 0.12298\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1342 - rmse: 0.3767 - mae: 0.3229 - smape: 69.9228 - coeff_determination: -16.2151\n",
      "Epoch 29/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1252 - rmse: 0.3538 - mae: 0.3145 - smape: 69.6109 - coeff_determination: -8.4290WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 29: loss did not improve from 0.12298\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1250 - rmse: 0.3501 - mae: 0.3145 - smape: 69.7609 - coeff_determination: -7.7640\n",
      "Epoch 30/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1213 - rmse: 0.3482 - mae: 0.3121 - smape: 70.4199 - coeff_determination: -7.9832WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 30: loss improved from 0.12298 to 0.12220, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.1222 - rmse: 0.3691 - mae: 0.3140 - smape: 70.3049 - coeff_determination: -44.4483\n",
      "Epoch 31/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1247 - rmse: 0.3531 - mae: 0.3136 - smape: 69.0047 - coeff_determination: -8.3645WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 31: loss did not improve from 0.12220\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1242 - rmse: 0.3411 - mae: 0.3130 - smape: 68.9322 - coeff_determination: -7.6031\n",
      "Epoch 32/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1274 - rmse: 0.3569 - mae: 0.3192 - smape: 72.1402 - coeff_determination: -8.5668WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 32: loss did not improve from 0.12220\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1270 - rmse: 0.3490 - mae: 0.3188 - smape: 71.9933 - coeff_determination: -8.0198\n",
      "Epoch 33/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1177 - rmse: 0.3430 - mae: 0.3070 - smape: 69.7003 - coeff_determination: -7.7391WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 33: loss improved from 0.12220 to 0.11871, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1187 - rmse: 0.3667 - mae: 0.3088 - smape: 69.9290 - coeff_determination: -12.7562\n",
      "Epoch 34/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1232 - rmse: 0.3510 - mae: 0.3135 - smape: 70.2051 - coeff_determination: -8.3221WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 34: loss did not improve from 0.11871\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1225 - rmse: 0.3331 - mae: 0.3126 - smape: 70.2108 - coeff_determination: -6.7271\n",
      "Epoch 35/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1180 - rmse: 0.3435 - mae: 0.3042 - smape: 67.6846 - coeff_determination: -7.8744WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 35: loss improved from 0.11871 to 0.11680, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.1168 - rmse: 0.3111 - mae: 0.3024 - smape: 67.6550 - coeff_determination: -7.8936\n",
      "Epoch 36/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1133 - rmse: 0.3366 - mae: 0.2980 - smape: 65.7113 - coeff_determination: -7.5153WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 36: loss improved from 0.11680 to 0.11459, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1146 - rmse: 0.3654 - mae: 0.2999 - smape: 65.5630 - coeff_determination: -7293.4707\n",
      "Epoch 37/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1109 - rmse: 0.3331 - mae: 0.2905 - smape: 62.4509 - coeff_determination: -7.5021WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 37: loss improved from 0.11459 to 0.11118, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.1112 - rmse: 0.3390 - mae: 0.2902 - smape: 62.5068 - coeff_determination: -6.0254\n",
      "Epoch 38/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1115 - rmse: 0.3340 - mae: 0.2854 - smape: 60.6903 - coeff_determination: -7.2637WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 38: loss improved from 0.11118 to 0.11068, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.1107 - rmse: 0.3114 - mae: 0.2837 - smape: 60.4356 - coeff_determination: -9.4782\n",
      "Epoch 39/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1087 - rmse: 0.3297 - mae: 0.2808 - smape: 59.2732 - coeff_determination: -7.2193WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 39: loss improved from 0.11068 to 0.10778, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1078 - rmse: 0.3048 - mae: 0.2789 - smape: 59.0139 - coeff_determination: -5.5047\n",
      "Epoch 40/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1166 - rmse: 0.3415 - mae: 0.2853 - smape: 59.0575 - coeff_determination: -7.6844WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 40: loss did not improve from 0.10778\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1159 - rmse: 0.3225 - mae: 0.2849 - smape: 59.6173 - coeff_determination: -12.1122\n",
      "Epoch 41/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1093 - rmse: 0.3306 - mae: 0.2794 - smape: 59.3001 - coeff_determination: -7.2176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 41: loss did not improve from 0.10778\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1105 - rmse: 0.3588 - mae: 0.2819 - smape: 59.4171 - coeff_determination: -13361.0498\n",
      "Epoch 42/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1056 - rmse: 0.3249 - mae: 0.2747 - smape: 58.7280 - coeff_determination: -6.7861WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 42: loss improved from 0.10778 to 0.10477, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.1048 - rmse: 0.3033 - mae: 0.2743 - smape: 58.9014 - coeff_determination: -10.1006\n",
      "Epoch 43/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1112 - rmse: 0.3334 - mae: 0.2860 - smape: 60.8027 - coeff_determination: -7.3015WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 43: loss did not improve from 0.10477\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1114 - rmse: 0.3389 - mae: 0.2861 - smape: 60.7860 - coeff_determination: -8.5098\n",
      "Epoch 44/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1081 - rmse: 0.3288 - mae: 0.2723 - smape: 58.3621 - coeff_determination: -7.0628WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 44: loss did not improve from 0.10477\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1092 - rmse: 0.3558 - mae: 0.2746 - smape: 58.4174 - coeff_determination: -184.1497\n",
      "Epoch 45/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1041 - rmse: 0.3226 - mae: 0.2712 - smape: 56.6569 - coeff_determination: -6.8992WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 45: loss improved from 0.10477 to 0.10243, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.1024 - rmse: 0.2721 - mae: 0.2690 - smape: 56.8618 - coeff_determination: -103.2544\n",
      "Epoch 46/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1017 - rmse: 0.3189 - mae: 0.2647 - smape: 56.0568 - coeff_determination: -6.6558WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 46: loss improved from 0.10243 to 0.10172, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.1017 - rmse: 0.3202 - mae: 0.2645 - smape: 55.9907 - coeff_determination: -6.3273\n",
      "Epoch 47/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1017 - rmse: 0.3190 - mae: 0.2628 - smape: 55.6108 - coeff_determination: -6.5280WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 47: loss improved from 0.10172 to 0.10131, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.1013 - rmse: 0.3076 - mae: 0.2629 - smape: 55.3968 - coeff_determination: -41.1270\n",
      "Epoch 48/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1044 - rmse: 0.3232 - mae: 0.2661 - smape: 56.1104 - coeff_determination: -6.7347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 48: loss did not improve from 0.10131\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1047 - rmse: 0.3288 - mae: 0.2672 - smape: 55.9720 - coeff_determination: -39.3119\n",
      "Epoch 49/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0967 - rmse: 0.3109 - mae: 0.2576 - smape: 53.7023 - coeff_determination: -6.0686WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 49: loss improved from 0.10131 to 0.09651, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 221ms/step - loss: 0.0965 - rmse: 0.3065 - mae: 0.2583 - smape: 53.9894 - coeff_determination: -24.4791\n",
      "Epoch 50/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0950 - rmse: 0.3082 - mae: 0.2544 - smape: 52.5706 - coeff_determination: -6.0545WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 50: loss improved from 0.09651 to 0.09380, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.0938 - rmse: 0.2715 - mae: 0.2525 - smape: 52.4545 - coeff_determination: -11.5002\n",
      "Epoch 51/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0939 - rmse: 0.3064 - mae: 0.2506 - smape: 52.8702 - coeff_determination: -5.9491WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 51: loss did not improve from 0.09380\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0946 - rmse: 0.3255 - mae: 0.2526 - smape: 52.8845 - coeff_determination: -62.9115\n",
      "Epoch 52/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0898 - rmse: 0.2997 - mae: 0.2415 - smape: 50.1032 - coeff_determination: -5.7903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 52: loss improved from 0.09380 to 0.08881, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0888 - rmse: 0.2695 - mae: 0.2406 - smape: 50.5225 - coeff_determination: -52.0774\n",
      "Epoch 53/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0957 - rmse: 0.3094 - mae: 0.2476 - smape: 51.1548 - coeff_determination: -6.3183WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 53: loss did not improve from 0.08881\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0960 - rmse: 0.3158 - mae: 0.2476 - smape: 51.1111 - coeff_determination: -5.2027\n",
      "Epoch 54/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0843 - rmse: 0.2904 - mae: 0.2359 - smape: 49.8110 - coeff_determination: -5.4010WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 54: loss improved from 0.08881 to 0.08473, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0847 - rmse: 0.3012 - mae: 0.2363 - smape: 49.9285 - coeff_determination: -4.9188\n",
      "Epoch 55/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0872 - rmse: 0.2952 - mae: 0.2422 - smape: 50.6306 - coeff_determination: -5.4631WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 55: loss did not improve from 0.08473\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0868 - rmse: 0.2838 - mae: 0.2413 - smape: 50.5290 - coeff_determination: -7.2245\n",
      "Epoch 56/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0892 - rmse: 0.2986 - mae: 0.2437 - smape: 51.1945 - coeff_determination: -5.7220WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 56: loss did not improve from 0.08473\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0888 - rmse: 0.2883 - mae: 0.2429 - smape: 51.0105 - coeff_determination: -4.9590\n",
      "Epoch 57/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0864 - rmse: 0.2939 - mae: 0.2424 - smape: 50.7895 - coeff_determination: -5.4391WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 57: loss did not improve from 0.08473\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0876 - rmse: 0.3240 - mae: 0.2443 - smape: 50.8052 - coeff_determination: -102.1669\n",
      "Epoch 58/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0798 - rmse: 0.2824 - mae: 0.2310 - smape: 48.4750 - coeff_determination: -4.9973WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 58: loss improved from 0.08473 to 0.07980, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0798 - rmse: 0.2833 - mae: 0.2313 - smape: 48.5108 - coeff_determination: -4.8579\n",
      "Epoch 59/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0824 - rmse: 0.2871 - mae: 0.2320 - smape: 48.5882 - coeff_determination: -5.1420WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 59: loss did not improve from 0.07980\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0842 - rmse: 0.3306 - mae: 0.2349 - smape: 48.8135 - coeff_determination: -118.2125\n",
      "Epoch 60/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0863 - rmse: 0.2937 - mae: 0.2327 - smape: 47.3118 - coeff_determination: -5.4672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 60: loss did not improve from 0.07980\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0860 - rmse: 0.2857 - mae: 0.2328 - smape: 47.5149 - coeff_determination: -5.2103\n",
      "Epoch 61/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0812 - rmse: 0.2850 - mae: 0.2302 - smape: 47.8656 - coeff_determination: -5.0635WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 61: loss did not improve from 0.07980\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0818 - rmse: 0.3018 - mae: 0.2318 - smape: 47.8690 - coeff_determination: -139.5835\n",
      "Epoch 62/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0771 - rmse: 0.2776 - mae: 0.2206 - smape: 45.6906 - coeff_determination: -4.6986WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 62: loss improved from 0.07980 to 0.07746, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0775 - rmse: 0.2891 - mae: 0.2207 - smape: 45.3382 - coeff_determination: -23.9317\n",
      "Epoch 63/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0793 - rmse: 0.2816 - mae: 0.2210 - smape: 45.1502 - coeff_determination: -4.9638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 63: loss did not improve from 0.07746\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0809 - rmse: 0.3221 - mae: 0.2235 - smape: 45.2851 - coeff_determination: -25889.7871\n",
      "Epoch 64/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0749 - rmse: 0.2737 - mae: 0.2162 - smape: 43.7171 - coeff_determination: -4.6833WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 64: loss improved from 0.07746 to 0.07654, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.0765 - rmse: 0.3158 - mae: 0.2181 - smape: 44.1661 - coeff_determination: -5.4804\n",
      "Epoch 65/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0732 - rmse: 0.2706 - mae: 0.2105 - smape: 43.2102 - coeff_determination: -4.4228WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 65: loss improved from 0.07654 to 0.07593, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0759 - rmse: 0.3370 - mae: 0.2145 - smape: 43.8206 - coeff_determination: -21.0839\n",
      "Epoch 66/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0721 - rmse: 0.2684 - mae: 0.2130 - smape: 43.5497 - coeff_determination: -4.4139WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 66: loss improved from 0.07593 to 0.07311, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0731 - rmse: 0.2977 - mae: 0.2143 - smape: 43.5318 - coeff_determination: -36356.9258\n",
      "Epoch 67/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0721 - rmse: 0.2686 - mae: 0.2136 - smape: 43.3848 - coeff_determination: -4.3431WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 67: loss improved from 0.07311 to 0.07148, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0715 - rmse: 0.2469 - mae: 0.2134 - smape: 43.7213 - coeff_determination: -6.6339\n",
      "Epoch 68/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0696 - rmse: 0.2637 - mae: 0.2115 - smape: 43.4911 - coeff_determination: -4.1717WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 68: loss improved from 0.07148 to 0.06958, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0696 - rmse: 0.2641 - mae: 0.2122 - smape: 43.5480 - coeff_determination: -5.7551\n",
      "Epoch 69/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0664 - rmse: 0.2577 - mae: 0.2121 - smape: 43.9635 - coeff_determination: -3.9662WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 69: loss improved from 0.06958 to 0.06522, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 232ms/step - loss: 0.0652 - rmse: 0.2105 - mae: 0.2097 - smape: 43.7356 - coeff_determination: -17.3243\n",
      "Epoch 70/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0686 - rmse: 0.2619 - mae: 0.2103 - smape: 43.0654 - coeff_determination: -4.1520WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 70: loss did not improve from 0.06522\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0678 - rmse: 0.2343 - mae: 0.2092 - smape: 42.8818 - coeff_determination: -3.1278\n",
      "Epoch 71/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0651 - rmse: 0.2552 - mae: 0.2059 - smape: 42.3886 - coeff_determination: -3.9419WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 71: loss improved from 0.06522 to 0.06423, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0642 - rmse: 0.2216 - mae: 0.2042 - smape: 41.9646 - coeff_determination: -2.4746\n",
      "Epoch 72/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0679 - rmse: 0.2606 - mae: 0.2070 - smape: 42.4331 - coeff_determination: -4.1125WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 72: loss did not improve from 0.06423\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0677 - rmse: 0.2544 - mae: 0.2067 - smape: 42.4205 - coeff_determination: -3.6723\n",
      "Epoch 73/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0650 - rmse: 0.2550 - mae: 0.2026 - smape: 40.8694 - coeff_determination: -3.8123WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 73: loss did not improve from 0.06423\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0646 - rmse: 0.2415 - mae: 0.2021 - smape: 40.5840 - coeff_determination: -16.1688\n",
      "Epoch 74/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - rmse: 0.2425 - mae: 0.1893 - smape: 36.4937 - coeff_determination: -3.4112WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 74: loss improved from 0.06423 to 0.05927, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0593 - rmse: 0.2575 - mae: 0.1900 - smape: 36.3931 - coeff_determination: -799.0057\n",
      "Epoch 75/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - rmse: 0.2469 - mae: 0.1926 - smape: 36.4340 - coeff_determination: -3.6423WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 75: loss did not improve from 0.05927\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0601 - rmse: 0.2146 - mae: 0.1910 - smape: 36.6847 - coeff_determination: -15.1649\n",
      "Epoch 76/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0606 - rmse: 0.2461 - mae: 0.1891 - smape: 35.9054 - coeff_determination: -3.5268WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 76: loss did not improve from 0.05927\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0598 - rmse: 0.2181 - mae: 0.1883 - smape: 35.6574 - coeff_determination: -3.1582\n",
      "Epoch 77/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0558 - rmse: 0.2362 - mae: 0.1823 - smape: 34.6844 - coeff_determination: -3.1919WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 77: loss improved from 0.05927 to 0.05521, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0552 - rmse: 0.2144 - mae: 0.1815 - smape: 34.4133 - coeff_determination: -2.4218\n",
      "Epoch 78/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0538 - rmse: 0.2319 - mae: 0.1738 - smape: 32.1352 - coeff_determination: -2.9737WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 78: loss improved from 0.05521 to 0.05376, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0538 - rmse: 0.2318 - mae: 0.1741 - smape: 32.2334 - coeff_determination: -5.0744\n",
      "Epoch 79/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - rmse: 0.2424 - mae: 0.1913 - smape: 36.5698 - coeff_determination: -3.4676WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 79: loss did not improve from 0.05376\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0582 - rmse: 0.2226 - mae: 0.1900 - smape: 36.4491 - coeff_determination: -2.3570\n",
      "Epoch 80/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0541 - rmse: 0.2327 - mae: 0.1826 - smape: 35.2476 - coeff_determination: -3.1219WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 80: loss improved from 0.05376 to 0.05312, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0531 - rmse: 0.1881 - mae: 0.1811 - smape: 35.3447 - coeff_determination: -3.9409\n",
      "Epoch 81/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0549 - rmse: 0.2343 - mae: 0.1792 - smape: 34.4958 - coeff_determination: -3.1260WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 81: loss did not improve from 0.05312\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0562 - rmse: 0.2739 - mae: 0.1815 - smape: 34.5020 - coeff_determination: -7521.3696\n",
      "Epoch 82/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0548 - rmse: 0.2341 - mae: 0.1804 - smape: 33.9618 - coeff_determination: -3.1198WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 82: loss did not improve from 0.05312\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0535 - rmse: 0.1735 - mae: 0.1778 - smape: 33.5900 - coeff_determination: -3.4792\n",
      "Epoch 83/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0581 - rmse: 0.2411 - mae: 0.1892 - smape: 37.8173 - coeff_determination: -3.4365WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 83: loss did not improve from 0.05312\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0579 - rmse: 0.2335 - mae: 0.1885 - smape: 37.7116 - coeff_determination: -2.5200\n",
      "Epoch 84/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - rmse: 0.2299 - mae: 0.1809 - smape: 34.5060 - coeff_determination: -2.9448WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 84: loss improved from 0.05312 to 0.05247, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0525 - rmse: 0.2154 - mae: 0.1805 - smape: 34.6142 - coeff_determination: -4.3117\n",
      "Epoch 85/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0494 - rmse: 0.2224 - mae: 0.1765 - smape: 35.0520 - coeff_determination: -2.6820WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 85: loss improved from 0.05247 to 0.04855, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 214ms/step - loss: 0.0485 - rmse: 0.1818 - mae: 0.1747 - smape: 34.5409 - coeff_determination: -1.8729\n",
      "Epoch 86/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - rmse: 0.2250 - mae: 0.1772 - smape: 33.7678 - coeff_determination: -2.8233WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 86: loss did not improve from 0.04855\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0500 - rmse: 0.1969 - mae: 0.1760 - smape: 33.5834 - coeff_determination: -2.0123\n",
      "Epoch 87/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0477 - rmse: 0.2184 - mae: 0.1681 - smape: 32.9453 - coeff_determination: -2.5202WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 87: loss improved from 0.04855 to 0.04742, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0474 - rmse: 0.2066 - mae: 0.1680 - smape: 32.7336 - coeff_determination: -17.0962\n",
      "Epoch 88/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0518 - rmse: 0.2275 - mae: 0.1797 - smape: 34.0627 - coeff_determination: -2.8638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 88: loss did not improve from 0.04742\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0516 - rmse: 0.2200 - mae: 0.1794 - smape: 33.8080 - coeff_determination: -2.9852\n",
      "Epoch 89/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0466 - rmse: 0.2158 - mae: 0.1679 - smape: 30.2743 - coeff_determination: -2.5380WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 89: loss improved from 0.04742 to 0.04679, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0468 - rmse: 0.2232 - mae: 0.1682 - smape: 30.3947 - coeff_determination: -2.2502\n",
      "Epoch 90/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0498 - rmse: 0.2231 - mae: 0.1696 - smape: 31.8721 - coeff_determination: -2.6932WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 90: loss did not improve from 0.04679\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0506 - rmse: 0.2503 - mae: 0.1715 - smape: 32.0366 - coeff_determination: -41.4919\n",
      "Epoch 91/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0491 - rmse: 0.2216 - mae: 0.1717 - smape: 31.9837 - coeff_determination: -2.6606WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 91: loss did not improve from 0.04679\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0500 - rmse: 0.2493 - mae: 0.1724 - smape: 32.0045 - coeff_determination: -4.6947\n",
      "Epoch 92/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0468 - rmse: 0.2163 - mae: 0.1667 - smape: 31.7920 - coeff_determination: -2.4351WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 92: loss improved from 0.04679 to 0.04650, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0465 - rmse: 0.2055 - mae: 0.1668 - smape: 31.6003 - coeff_determination: -22.6857\n",
      "Epoch 93/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0423 - rmse: 0.2056 - mae: 0.1584 - smape: 29.7374 - coeff_determination: -2.1359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 93: loss improved from 0.04650 to 0.04331, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0433 - rmse: 0.2414 - mae: 0.1597 - smape: 30.0094 - coeff_determination: -6.1670\n",
      "Epoch 94/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0507 - rmse: 0.2251 - mae: 0.1790 - smape: 34.8916 - coeff_determination: -2.8110WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 94: loss did not improve from 0.04331\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0511 - rmse: 0.2380 - mae: 0.1796 - smape: 35.0466 - coeff_determination: -3.1271\n",
      "Epoch 95/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0467 - rmse: 0.2161 - mae: 0.1708 - smape: 34.0322 - coeff_determination: -2.5112WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 95: loss did not improve from 0.04331\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0487 - rmse: 0.2747 - mae: 0.1740 - smape: 34.3562 - coeff_determination: -12160.0303\n",
      "Epoch 96/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0497 - rmse: 0.2229 - mae: 0.1729 - smape: 32.8166 - coeff_determination: -2.7511WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 96: loss did not improve from 0.04331\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0494 - rmse: 0.2115 - mae: 0.1722 - smape: 32.6318 - coeff_determination: -2.1402\n",
      "Epoch 97/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0362 - rmse: 0.1902 - mae: 0.1480 - smape: 27.5072 - coeff_determination: -1.6960WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 97: loss improved from 0.04331 to 0.03620, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0362 - rmse: 0.1906 - mae: 0.1481 - smape: 27.6312 - coeff_determination: -2.1852\n",
      "Epoch 98/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0469 - rmse: 0.2166 - mae: 0.1678 - smape: 32.6356 - coeff_determination: -2.4802WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 98: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0475 - rmse: 0.2363 - mae: 0.1689 - smape: 32.7446 - coeff_determination: -6.3960\n",
      "Epoch 99/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - rmse: 0.2116 - mae: 0.1604 - smape: 29.3778 - coeff_determination: -2.3566WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 99: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0441 - rmse: 0.1790 - mae: 0.1592 - smape: 29.2595 - coeff_determination: -1.7962\n",
      "Epoch 100/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0423 - rmse: 0.2057 - mae: 0.1559 - smape: 29.0401 - coeff_determination: -2.2004WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 100: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0421 - rmse: 0.1956 - mae: 0.1559 - smape: 29.0500 - coeff_determination: -1.6528\n",
      "Epoch 101/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0409 - rmse: 0.2022 - mae: 0.1523 - smape: 26.1039 - coeff_determination: -2.0840WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 101: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0404 - rmse: 0.1798 - mae: 0.1518 - smape: 26.4941 - coeff_determination: -67.2077\n",
      "Epoch 102/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0403 - rmse: 0.2007 - mae: 0.1491 - smape: 26.6648 - coeff_determination: -1.9820WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 102: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0413 - rmse: 0.2373 - mae: 0.1513 - smape: 27.0073 - coeff_determination: -21.0637\n",
      "Epoch 103/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0368 - rmse: 0.1918 - mae: 0.1447 - smape: 26.2696 - coeff_determination: -1.7273WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 103: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0367 - rmse: 0.1901 - mae: 0.1452 - smape: 26.1703 - coeff_determination: -10.8959\n",
      "Epoch 104/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0416 - rmse: 0.2040 - mae: 0.1563 - smape: 28.5085 - coeff_determination: -2.1110WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 104: loss did not improve from 0.03620\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0420 - rmse: 0.2182 - mae: 0.1563 - smape: 28.4506 - coeff_determination: -3.1016\n",
      "Epoch 105/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0347 - rmse: 0.1864 - mae: 0.1423 - smape: 25.6273 - coeff_determination: -1.5989WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 105: loss improved from 0.03620 to 0.03561, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.0356 - rmse: 0.2192 - mae: 0.1443 - smape: 25.7517 - coeff_determination: -107.7856\n",
      "Epoch 106/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - rmse: 0.1944 - mae: 0.1512 - smape: 27.9249 - coeff_determination: -1.8229WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 106: loss did not improve from 0.03561\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0371 - rmse: 0.1544 - mae: 0.1496 - smape: 27.7201 - coeff_determination: -1.1860\n",
      "Epoch 107/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0316 - rmse: 0.1778 - mae: 0.1399 - smape: 26.2641 - coeff_determination: -1.3541WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 107: loss improved from 0.03561 to 0.03211, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.0321 - rmse: 0.1982 - mae: 0.1409 - smape: 26.5594 - coeff_determination: -2.6701\n",
      "Epoch 108/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - rmse: 0.1838 - mae: 0.1454 - smape: 25.9093 - coeff_determination: -1.4727WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 108: loss did not improve from 0.03211\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0338 - rmse: 0.1864 - mae: 0.1463 - smape: 26.1338 - coeff_determination: -6.6079\n",
      "Epoch 109/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0306 - rmse: 0.1749 - mae: 0.1355 - smape: 24.0704 - coeff_determination: -1.2614WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 109: loss improved from 0.03211 to 0.03105, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0310 - rmse: 0.1939 - mae: 0.1358 - smape: 24.0674 - coeff_determination: -6.2242\n",
      "Epoch 110/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0357 - rmse: 0.1890 - mae: 0.1452 - smape: 24.3659 - coeff_determination: -1.7154WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 110: loss did not improve from 0.03105\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0359 - rmse: 0.1958 - mae: 0.1456 - smape: 24.6611 - coeff_determination: -1.4732\n",
      "Epoch 111/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0367 - rmse: 0.1915 - mae: 0.1497 - smape: 24.8677 - coeff_determination: -1.8378WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 111: loss did not improve from 0.03105\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0360 - rmse: 0.1547 - mae: 0.1481 - smape: 24.8768 - coeff_determination: -17.6333\n",
      "Epoch 112/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0299 - rmse: 0.1730 - mae: 0.1381 - smape: 22.7943 - coeff_determination: -1.2422WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 112: loss improved from 0.03105 to 0.02988, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 215ms/step - loss: 0.0299 - rmse: 0.1710 - mae: 0.1377 - smape: 22.8108 - coeff_determination: -1.7944\n",
      "Epoch 113/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - rmse: 0.1838 - mae: 0.1429 - smape: 24.9856 - coeff_determination: -1.5346WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 113: loss did not improve from 0.02988\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0343 - rmse: 0.2059 - mae: 0.1441 - smape: 24.9696 - coeff_determination: -559.0131\n",
      "Epoch 114/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0337 - rmse: 0.1837 - mae: 0.1386 - smape: 23.4312 - coeff_determination: -1.5207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 114: loss did not improve from 0.02988\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0344 - rmse: 0.2105 - mae: 0.1408 - smape: 23.5977 - coeff_determination: -111.7820\n",
      "Epoch 115/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - rmse: 0.1789 - mae: 0.1366 - smape: 24.3782 - coeff_determination: -1.3612WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 115: loss did not improve from 0.02988\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0320 - rmse: 0.1783 - mae: 0.1370 - smape: 24.3235 - coeff_determination: -16.1813\n",
      "Epoch 116/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0319 - rmse: 0.1787 - mae: 0.1341 - smape: 24.4850 - coeff_determination: -1.4002WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 116: loss did not improve from 0.02988\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0328 - rmse: 0.2134 - mae: 0.1359 - smape: 24.6566 - coeff_determination: -12201.5664\n",
      "Epoch 117/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0327 - rmse: 0.1809 - mae: 0.1390 - smape: 25.3546 - coeff_determination: -1.4420WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 117: loss did not improve from 0.02988\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0338 - rmse: 0.2217 - mae: 0.1413 - smape: 25.5352 - coeff_determination: -51.7477\n",
      "Epoch 118/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0302 - rmse: 0.1737 - mae: 0.1303 - smape: 23.6654 - coeff_determination: -1.2182WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 118: loss improved from 0.02988 to 0.02970, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0297 - rmse: 0.1460 - mae: 0.1295 - smape: 23.4932 - coeff_determination: -1.8850\n",
      "Epoch 119/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - rmse: 0.1799 - mae: 0.1412 - smape: 24.7965 - coeff_determination: -1.4284WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 119: loss did not improve from 0.02970\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0319 - rmse: 0.1574 - mae: 0.1397 - smape: 24.5762 - coeff_determination: -3.0468\n",
      "Epoch 120/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0322 - rmse: 0.1796 - mae: 0.1361 - smape: 23.7321 - coeff_determination: -1.3843WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 120: loss did not improve from 0.02970\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0324 - rmse: 0.1862 - mae: 0.1354 - smape: 23.4657 - coeff_determination: -9.5492\n",
      "Epoch 121/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0358 - rmse: 0.1892 - mae: 0.1448 - smape: 25.7125 - coeff_determination: -1.6874WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 121: loss did not improve from 0.02970\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0361 - rmse: 0.2032 - mae: 0.1454 - smape: 25.7593 - coeff_determination: -2.0830\n",
      "Epoch 122/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0280 - rmse: 0.1673 - mae: 0.1322 - smape: 24.1027 - coeff_determination: -1.1194WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 122: loss improved from 0.02970 to 0.02785, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 0.0278 - rmse: 0.1593 - mae: 0.1317 - smape: 24.0831 - coeff_determination: -0.8561\n",
      "Epoch 123/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0341 - rmse: 0.1845 - mae: 0.1420 - smape: 25.2516 - coeff_determination: -1.5238WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 123: loss did not improve from 0.02785\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0344 - rmse: 0.1969 - mae: 0.1434 - smape: 25.4040 - coeff_determination: -4.2204\n",
      "Epoch 124/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0244 - rmse: 0.1564 - mae: 0.1193 - smape: 20.9022 - coeff_determination: -0.8635WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 124: loss improved from 0.02785 to 0.02404, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0240 - rmse: 0.1303 - mae: 0.1183 - smape: 20.7616 - coeff_determination: -0.2095\n",
      "Epoch 125/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0329 - rmse: 0.1814 - mae: 0.1394 - smape: 23.5264 - coeff_determination: -1.4450WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 125: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0322 - rmse: 0.1442 - mae: 0.1375 - smape: 23.3756 - coeff_determination: -2.1643\n",
      "Epoch 126/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - rmse: 0.1641 - mae: 0.1249 - smape: 20.5199 - coeff_determination: -1.0190WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 126: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0277 - rmse: 0.1947 - mae: 0.1270 - smape: 20.7253 - coeff_determination: -160.4056\n",
      "Epoch 127/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0283 - rmse: 0.1683 - mae: 0.1295 - smape: 20.6448 - coeff_determination: -1.1135WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 127: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0284 - rmse: 0.1734 - mae: 0.1305 - smape: 20.5591 - coeff_determination: -37.2834\n",
      "Epoch 128/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0232 - rmse: 0.1524 - mae: 0.1152 - smape: 19.6497 - coeff_determination: -0.7516WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 128: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0243 - rmse: 0.1965 - mae: 0.1169 - smape: 19.9780 - coeff_determination: -1.7330\n",
      "Epoch 129/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0259 - rmse: 0.1609 - mae: 0.1261 - smape: 21.1013 - coeff_determination: -0.9572WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 129: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0254 - rmse: 0.1309 - mae: 0.1247 - smape: 21.1039 - coeff_determination: -24.7230\n",
      "Epoch 130/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0255 - rmse: 0.1598 - mae: 0.1214 - smape: 20.2010 - coeff_determination: -0.8936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 130: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0267 - rmse: 0.2058 - mae: 0.1239 - smape: 20.5581 - coeff_determination: -25.7673\n",
      "Epoch 131/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0249 - rmse: 0.1577 - mae: 0.1216 - smape: 20.7549 - coeff_determination: -0.8650WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 131: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0260 - rmse: 0.2046 - mae: 0.1245 - smape: 21.0660 - coeff_determination: -3500.8752\n",
      "Epoch 132/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0263 - rmse: 0.1620 - mae: 0.1235 - smape: 20.2974 - coeff_determination: -0.9815WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 132: loss did not improve from 0.02404\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0258 - rmse: 0.1356 - mae: 0.1222 - smape: 20.2833 - coeff_determination: -8.8314\n",
      "Epoch 133/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0213 - rmse: 0.1459 - mae: 0.1115 - smape: 18.1214 - coeff_determination: -0.6027WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 133: loss improved from 0.02404 to 0.02115, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 0.0211 - rmse: 0.1376 - mae: 0.1110 - smape: 18.0942 - coeff_determination: -0.3719\n",
      "Epoch 134/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - rmse: 0.1526 - mae: 0.1180 - smape: 19.4466 - coeff_determination: -0.7831WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 134: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0231 - rmse: 0.1411 - mae: 0.1176 - smape: 19.3635 - coeff_determination: -0.2925\n",
      "Epoch 135/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0221 - rmse: 0.1486 - mae: 0.1115 - smape: 18.1827 - coeff_determination: -0.6542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 135: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0229 - rmse: 0.1867 - mae: 0.1136 - smape: 18.4147 - coeff_determination: -4368.9258\n",
      "Epoch 136/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - rmse: 0.1640 - mae: 0.1223 - smape: 20.0113 - coeff_determination: -1.0235WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 136: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0271 - rmse: 0.1752 - mae: 0.1227 - smape: 20.2036 - coeff_determination: -1.6132\n",
      "Epoch 137/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0230 - rmse: 0.1517 - mae: 0.1157 - smape: 18.5854 - coeff_determination: -0.7318WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 137: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0228 - rmse: 0.1353 - mae: 0.1150 - smape: 18.5210 - coeff_determination: -0.3604\n",
      "Epoch 138/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0236 - rmse: 0.1535 - mae: 0.1167 - smape: 18.5062 - coeff_determination: -0.7506WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 138: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0232 - rmse: 0.1306 - mae: 0.1158 - smape: 18.3834 - coeff_determination: -0.7524\n",
      "Epoch 139/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0252 - rmse: 0.1587 - mae: 0.1212 - smape: 19.1194 - coeff_determination: -0.9012WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 139: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0250 - rmse: 0.1472 - mae: 0.1210 - smape: 19.0228 - coeff_determination: -0.5239\n",
      "Epoch 140/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0240 - rmse: 0.1550 - mae: 0.1180 - smape: 20.1844 - coeff_determination: -0.7775WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 140: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0245 - rmse: 0.1762 - mae: 0.1191 - smape: 20.2662 - coeff_determination: -16.8459\n",
      "Epoch 141/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - rmse: 0.1525 - mae: 0.1197 - smape: 20.5273 - coeff_determination: -0.7476WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 141: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0228 - rmse: 0.1208 - mae: 0.1184 - smape: 20.2330 - coeff_determination: -0.1579\n",
      "Epoch 142/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0245 - rmse: 0.1564 - mae: 0.1212 - smape: 21.4811 - coeff_determination: -0.8404WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 142: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0241 - rmse: 0.1339 - mae: 0.1202 - smape: 21.5084 - coeff_determination: -0.8919\n",
      "Epoch 143/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0239 - rmse: 0.1546 - mae: 0.1182 - smape: 20.1693 - coeff_determination: -0.7920WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 143: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0236 - rmse: 0.1345 - mae: 0.1175 - smape: 20.1591 - coeff_determination: -0.5024\n",
      "Epoch 144/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0275 - rmse: 0.1658 - mae: 0.1267 - smape: 21.2671 - coeff_determination: -1.0324WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 144: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0275 - rmse: 0.1648 - mae: 0.1269 - smape: 21.3930 - coeff_determination: -2.4269\n",
      "Epoch 145/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0229 - rmse: 0.1512 - mae: 0.1163 - smape: 18.3346 - coeff_determination: -0.7495WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 145: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0235 - rmse: 0.1799 - mae: 0.1170 - smape: 18.5029 - coeff_determination: -0.9178\n",
      "Epoch 146/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0234 - rmse: 0.1531 - mae: 0.1186 - smape: 18.8604 - coeff_determination: -0.7718WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 146: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0231 - rmse: 0.1350 - mae: 0.1175 - smape: 18.7667 - coeff_determination: -0.8432\n",
      "Epoch 147/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0229 - rmse: 0.1514 - mae: 0.1162 - smape: 17.8879 - coeff_determination: -0.7056WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 147: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0226 - rmse: 0.1350 - mae: 0.1157 - smape: 17.7884 - coeff_determination: -0.5953\n",
      "Epoch 148/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0232 - rmse: 0.1523 - mae: 0.1165 - smape: 18.0407 - coeff_determination: -0.7192WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 148: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0238 - rmse: 0.1787 - mae: 0.1184 - smape: 18.2887 - coeff_determination: -15.5423\n",
      "Epoch 149/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0223 - rmse: 0.1492 - mae: 0.1129 - smape: 17.6882 - coeff_determination: -0.6684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 149: loss did not improve from 0.02115\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0220 - rmse: 0.1306 - mae: 0.1124 - smape: 17.6961 - coeff_determination: -0.5196\n",
      "Epoch 150/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0208 - rmse: 0.1443 - mae: 0.1099 - smape: 18.2488 - coeff_determination: -0.5406WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 150: loss improved from 0.02115 to 0.02086, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0209 - rmse: 0.1460 - mae: 0.1100 - smape: 18.1693 - coeff_determination: -2.5536\n",
      "Epoch 151/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0187 - rmse: 0.1367 - mae: 0.1050 - smape: 16.7518 - coeff_determination: -0.3855WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 151: loss improved from 0.02086 to 0.01869, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 222ms/step - loss: 0.0187 - rmse: 0.1364 - mae: 0.1048 - smape: 16.6334 - coeff_determination: -1.3499\n",
      "Epoch 152/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0211 - rmse: 0.1454 - mae: 0.1110 - smape: 17.6326 - coeff_determination: -0.5954WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 152: loss did not improve from 0.01869\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0209 - rmse: 0.1269 - mae: 0.1103 - smape: 17.6154 - coeff_determination: -0.3066\n",
      "Epoch 153/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - rmse: 0.1309 - mae: 0.1045 - smape: 16.7506 - coeff_determination: -0.3131WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 153: loss improved from 0.01869 to 0.01683, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 0.0168 - rmse: 0.1058 - mae: 0.1035 - smape: 16.7686 - coeff_determination: -3.8025\n",
      "Epoch 154/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0247 - rmse: 0.1573 - mae: 0.1198 - smape: 20.7858 - coeff_determination: -0.8572WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 154: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0252 - rmse: 0.1770 - mae: 0.1217 - smape: 20.8093 - coeff_determination: -6781.8276\n",
      "Epoch 155/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0192 - rmse: 0.1385 - mae: 0.1087 - smape: 16.9376 - coeff_determination: -0.4226WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 155: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0190 - rmse: 0.1271 - mae: 0.1084 - smape: 16.9502 - coeff_determination: -0.7221\n",
      "Epoch 156/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0220 - rmse: 0.1482 - mae: 0.1140 - smape: 18.8371 - coeff_determination: -0.6335WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 156: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0217 - rmse: 0.1337 - mae: 0.1135 - smape: 18.6718 - coeff_determination: -0.7834\n",
      "Epoch 157/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0210 - rmse: 0.1449 - mae: 0.1095 - smape: 18.3729 - coeff_determination: -0.5726WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 157: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0212 - rmse: 0.1562 - mae: 0.1107 - smape: 18.3755 - coeff_determination: -6532.1660\n",
      "Epoch 158/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0205 - rmse: 0.1431 - mae: 0.1123 - smape: 18.8365 - coeff_determination: -0.5166WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 158: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0213 - rmse: 0.1809 - mae: 0.1140 - smape: 19.3602 - coeff_determination: -5.3802\n",
      "Epoch 159/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0251 - rmse: 0.1585 - mae: 0.1237 - smape: 21.7468 - coeff_determination: -0.8748WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 159: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0248 - rmse: 0.1381 - mae: 0.1228 - smape: 21.4823 - coeff_determination: -0.5802\n",
      "Epoch 160/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0202 - rmse: 0.1423 - mae: 0.1098 - smape: 18.4720 - coeff_determination: -0.5120WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 160: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0199 - rmse: 0.1197 - mae: 0.1086 - smape: 18.2276 - coeff_determination: -0.1741\n",
      "Epoch 161/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0194 - rmse: 0.1392 - mae: 0.1102 - smape: 17.8800 - coeff_determination: -0.4672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 161: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0191 - rmse: 0.1212 - mae: 0.1091 - smape: 17.6196 - coeff_determination: -0.0510\n",
      "Epoch 162/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0179 - rmse: 0.1337 - mae: 0.1027 - smape: 16.8069 - coeff_determination: -0.3510WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 162: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0176 - rmse: 0.1139 - mae: 0.1021 - smape: 16.8661 - coeff_determination: -0.0775\n",
      "Epoch 163/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0209 - rmse: 0.1447 - mae: 0.1104 - smape: 18.7284 - coeff_determination: -0.5304WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 163: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0211 - rmse: 0.1532 - mae: 0.1112 - smape: 18.7570 - coeff_determination: -72.2836\n",
      "Epoch 164/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0204 - rmse: 0.1427 - mae: 0.1069 - smape: 16.8186 - coeff_determination: -0.5501WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 164: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0202 - rmse: 0.1290 - mae: 0.1066 - smape: 16.7679 - coeff_determination: -0.1332\n",
      "Epoch 165/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0223 - rmse: 0.1493 - mae: 0.1144 - smape: 17.7643 - coeff_determination: -0.6869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 165: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0217 - rmse: 0.1057 - mae: 0.1125 - smape: 17.5042 - coeff_determination: -0.4497\n",
      "Epoch 166/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0202 - rmse: 0.1420 - mae: 0.1071 - smape: 16.2891 - coeff_determination: -0.5209WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 166: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0198 - rmse: 0.1122 - mae: 0.1056 - smape: 16.0168 - coeff_determination: 0.0209\n",
      "Epoch 167/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0200 - rmse: 0.1413 - mae: 0.1103 - smape: 18.0569 - coeff_determination: -0.4966WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 167: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0198 - rmse: 0.1309 - mae: 0.1098 - smape: 17.8161 - coeff_determination: -2097.3062\n",
      "Epoch 168/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0194 - rmse: 0.1393 - mae: 0.1054 - smape: 16.8585 - coeff_determination: -0.4373WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 168: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0193 - rmse: 0.1355 - mae: 0.1054 - smape: 16.7776 - coeff_determination: -5.3271\n",
      "Epoch 169/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0197 - rmse: 0.1405 - mae: 0.1097 - smape: 18.6570 - coeff_determination: -0.4598WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 169: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0199 - rmse: 0.1495 - mae: 0.1101 - smape: 18.6329 - coeff_determination: -10.9176\n",
      "Epoch 170/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0188 - rmse: 0.1371 - mae: 0.1067 - smape: 17.1048 - coeff_determination: -0.4074WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 170: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0191 - rmse: 0.1532 - mae: 0.1069 - smape: 17.0824 - coeff_determination: -95.5770\n",
      "Epoch 171/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0188 - rmse: 0.1370 - mae: 0.1045 - smape: 16.8151 - coeff_determination: -0.4347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 171: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0183 - rmse: 0.1006 - mae: 0.1029 - smape: 16.5721 - coeff_determination: 0.1829\n",
      "Epoch 172/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0208 - rmse: 0.1441 - mae: 0.1108 - smape: 18.0953 - coeff_determination: -0.5568WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 172: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0210 - rmse: 0.1556 - mae: 0.1118 - smape: 18.0235 - coeff_determination: -3299.8101\n",
      "Epoch 173/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0176 - rmse: 0.1327 - mae: 0.1000 - smape: 15.3426 - coeff_determination: -0.3050WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 173: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0176 - rmse: 0.1302 - mae: 0.1002 - smape: 15.3092 - coeff_determination: -6.0064\n",
      "Epoch 174/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0218 - rmse: 0.1476 - mae: 0.1155 - smape: 18.3194 - coeff_determination: -0.6192WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 174: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0218 - rmse: 0.1461 - mae: 0.1155 - smape: 18.2316 - coeff_determination: -1.0572\n",
      "Epoch 175/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0177 - rmse: 0.1332 - mae: 0.1035 - smape: 16.7486 - coeff_determination: -0.3125WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 175: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0182 - rmse: 0.1597 - mae: 0.1048 - smape: 16.9854 - coeff_determination: -3.9056\n",
      "Epoch 176/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0200 - rmse: 0.1414 - mae: 0.1120 - smape: 18.2262 - coeff_determination: -0.5099WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 176: loss did not improve from 0.01683\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0197 - rmse: 0.1239 - mae: 0.1116 - smape: 18.3492 - coeff_determination: -52.8178\n",
      "Epoch 177/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0158 - rmse: 0.1257 - mae: 0.0947 - smape: 14.4278 - coeff_determination: -0.1947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 177: loss improved from 0.01683 to 0.01578, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.0158 - rmse: 0.1237 - mae: 0.0947 - smape: 14.4236 - coeff_determination: -0.0581\n",
      "Epoch 178/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0203 - rmse: 0.1425 - mae: 0.1089 - smape: 16.6041 - coeff_determination: -0.5395WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 178: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0202 - rmse: 0.1378 - mae: 0.1094 - smape: 16.8191 - coeff_determination: -0.3087\n",
      "Epoch 179/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0195 - rmse: 0.1396 - mae: 0.1070 - smape: 17.1325 - coeff_determination: -0.4442WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 179: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0196 - rmse: 0.1445 - mae: 0.1072 - smape: 17.2654 - coeff_determination: -1.4390\n",
      "Epoch 180/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0193 - rmse: 0.1388 - mae: 0.1061 - smape: 16.3699 - coeff_determination: -0.4664WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 180: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0193 - rmse: 0.1387 - mae: 0.1061 - smape: 16.3899 - coeff_determination: -0.2376\n",
      "Epoch 181/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0186 - rmse: 0.1364 - mae: 0.1066 - smape: 17.3457 - coeff_determination: -0.3964WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 181: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0187 - rmse: 0.1414 - mae: 0.1068 - smape: 17.3622 - coeff_determination: -0.4831\n",
      "Epoch 182/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0169 - rmse: 0.1299 - mae: 0.0990 - smape: 15.9878 - coeff_determination: -0.2572WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 182: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0178 - rmse: 0.1733 - mae: 0.1006 - smape: 16.2327 - coeff_determination: -35.6867\n",
      "Epoch 183/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0193 - rmse: 0.1389 - mae: 0.1069 - smape: 17.3950 - coeff_determination: -0.4774WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 183: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0192 - rmse: 0.1348 - mae: 0.1065 - smape: 17.3638 - coeff_determination: -0.1447\n",
      "Epoch 184/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0178 - rmse: 0.1335 - mae: 0.1044 - smape: 17.9277 - coeff_determination: -0.3220WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 184: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0179 - rmse: 0.1367 - mae: 0.1044 - smape: 17.7844 - coeff_determination: -12.6203\n",
      "Epoch 185/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0204 - rmse: 0.1429 - mae: 0.1067 - smape: 16.7284 - coeff_determination: -0.5384WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 185: loss did not improve from 0.01578\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0206 - rmse: 0.1542 - mae: 0.1072 - smape: 16.8705 - coeff_determination: -0.7531\n",
      "Epoch 186/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0157 - rmse: 0.1255 - mae: 0.0948 - smape: 15.1905 - coeff_determination: -0.2061WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 186: loss improved from 0.01578 to 0.01542, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 218ms/step - loss: 0.0154 - rmse: 0.0980 - mae: 0.0935 - smape: 14.9384 - coeff_determination: 0.2797\n",
      "Epoch 187/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0177 - rmse: 0.1329 - mae: 0.1028 - smape: 15.7833 - coeff_determination: -0.3261WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 187: loss did not improve from 0.01542\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0175 - rmse: 0.1216 - mae: 0.1020 - smape: 15.7146 - coeff_determination: -0.1966\n",
      "Epoch 188/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0171 - rmse: 0.1309 - mae: 0.1013 - smape: 15.5489 - coeff_determination: -0.2791WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 188: loss did not improve from 0.01542\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0175 - rmse: 0.1511 - mae: 0.1024 - smape: 15.6405 - coeff_determination: -57.7932\n",
      "Epoch 189/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0164 - rmse: 0.1282 - mae: 0.1016 - smape: 15.2223 - coeff_determination: -0.2349WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 189: loss did not improve from 0.01542\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0175 - rmse: 0.1764 - mae: 0.1042 - smape: 15.5468 - coeff_determination: -4994.8271\n",
      "Epoch 190/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0197 - rmse: 0.1403 - mae: 0.1098 - smape: 16.3313 - coeff_determination: -0.4549WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 190: loss did not improve from 0.01542\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0194 - rmse: 0.1183 - mae: 0.1091 - smape: 16.1102 - coeff_determination: -0.9459\n",
      "Epoch 191/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0183 - rmse: 0.1354 - mae: 0.1040 - smape: 16.0135 - coeff_determination: -0.3698WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 191: loss did not improve from 0.01542\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0184 - rmse: 0.1364 - mae: 0.1041 - smape: 16.0454 - coeff_determination: -0.5350\n",
      "Epoch 192/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0153 - rmse: 0.1235 - mae: 0.0950 - smape: 14.9231 - coeff_determination: -0.1417WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 192: loss improved from 0.01542 to 0.01530, saving model to checkpoint/Transformer.best13072023_12:17:42.hdf5\n",
      "2/2 [==============================] - 0s 209ms/step - loss: 0.0153 - rmse: 0.1263 - mae: 0.0955 - smape: 14.8540 - coeff_determination: -28.2470\n",
      "Epoch 193/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0203 - rmse: 0.1425 - mae: 0.1117 - smape: 18.5323 - coeff_determination: -0.5468WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 193: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0204 - rmse: 0.1500 - mae: 0.1119 - smape: 18.7760 - coeff_determination: -0.4717\n",
      "Epoch 194/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0183 - rmse: 0.1353 - mae: 0.1042 - smape: 17.7341 - coeff_determination: -0.3556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 194: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0180 - rmse: 0.1168 - mae: 0.1035 - smape: 17.4913 - coeff_determination: -1.8763\n",
      "Epoch 195/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0158 - rmse: 0.1255 - mae: 0.0960 - smape: 15.2886 - coeff_determination: -0.1992WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 195: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0155 - rmse: 0.1060 - mae: 0.0953 - smape: 15.2485 - coeff_determination: 0.2030\n",
      "Epoch 196/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0159 - rmse: 0.1259 - mae: 0.0977 - smape: 15.7369 - coeff_determination: -0.1900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 196: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0161 - rmse: 0.1416 - mae: 0.0987 - smape: 15.7314 - coeff_determination: -2883.9114\n",
      "Epoch 197/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0179 - rmse: 0.1337 - mae: 0.1036 - smape: 15.8217 - coeff_determination: -0.3880WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 197: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0175 - rmse: 0.1009 - mae: 0.1021 - smape: 15.7924 - coeff_determination: -11.4425\n",
      "Epoch 198/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0184 - rmse: 0.1357 - mae: 0.1014 - smape: 15.3541 - coeff_determination: -0.3933WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 198: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0181 - rmse: 0.1111 - mae: 0.1006 - smape: 15.2701 - coeff_determination: -5.5412\n",
      "Epoch 199/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0177 - rmse: 0.1329 - mae: 0.1024 - smape: 15.8989 - coeff_determination: -0.3435WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 199: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0183 - rmse: 0.1658 - mae: 0.1038 - smape: 16.1924 - coeff_determination: -0.7231\n",
      "Epoch 200/200\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0165 - rmse: 0.1284 - mae: 0.0982 - smape: 15.1055 - coeff_determination: -0.2644WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,rmse,mae,smape,coeff_determination\n",
      "\n",
      "Epoch 200: loss did not improve from 0.01530\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0167 - rmse: 0.1398 - mae: 0.0987 - smape: 15.1417 - coeff_determination: -0.1654\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 0.0048 - rmse: 0.0694 - mae: 0.0573 - smape: 11.1906 - coeff_determination: -0.6854\n",
      "Result \n",
      " RMSE = 0.07  \n",
      " MAE = 0.06 \n",
      " R2 = -0.69\n"
     ]
    }
   ],
   "source": [
    "tr = Transformer()\n",
    "tr.train(X_train_reshaped,y_train_reshaped)\n",
    "_, rmse_result, mae_result, smape_result, r2_result = tr.evaluate(X_test_reshaped,y_test_reshaped)\n",
    "\n",
    "\n",
    "print('Result \\n RMSE = %.2f  \\n MAE = %.2f \\n R2 = %.2f' % (rmse_result,\n",
    "                                                                            mae_result,\n",
    "                                                                            r2_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
